paper_id,Title,Authors,Keyword,Abstract,Date,Field,Citations, 
1,CenterSnap SingleShot MultiObject 3D Shape Reconstruction and Categorical 6D Pose and Size Estimation,Muhammad Zubair Irshad Thomas Kollar Michael Laskey Kevin Stone Zsolt Kira,Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Robotics (cs.RO),"  This paper studies the complex task of simultaneous multi-object 3Dreconstruction, 6D pose and size estimation from a single-view RGB-Dobservation. In contrast to instance-level pose estimation, we focus on a morechallenging problem where CAD models are not available at inference time.Existing approaches mainly follow a complex multi-stage pipeline which firstlocalizes and detects each object instance in the image and then regresses toeither their 3D meshes or 6D poses. These approaches suffer fromhigh-computational cost and low performance in complex multi-object scenarios,where occlusions can be present. Hence, we present a simple one-stage approachto predict both the 3D shape and estimate the 6D pose and size jointly in abounding-box free manner. In particular, our method treats object instances asspatial centers where each center denotes the complete shape of an object alongwith its 6D pose and size. Through this per-pixel representation, our approachcan reconstruct in real-time (40 FPS) multiple novel object instances andpredict their 6D pose and sizes in a single-forward pass. Through extensiveexperiments, we demonstrate that our approach significantly outperforms allshape completion and categorical 6D pose and size estimation baselines onmulti-object ShapeNet and NOCS datasets respectively with a 12.6% absoluteimprovement in mAP for 6D pose for novel real-world object instances.    ",2022/03/03,Computer Vision,65,
2,Recovering 3D Human Mesh from Monocular Images A Survey,Yating Tian Hongwen Zhang Yebin Liu Limin Wang,Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR),"  Estimating human pose and shape from monocular images is a long-standingproblem in computer vision. Since the release of statistical body models, 3Dhuman mesh recovery has been drawing broader attention. With the same goal ofobtaining well-aligned and physically plausible mesh results, two paradigmshave been developed to overcome challenges in the 2D-to-3D lifting process: i)an optimization-based paradigm, where different data terms and regularizationterms are exploited as optimization objectives; and ii) a regression-basedparadigm, where deep learning techniques are embraced to solve the problem inan end-to-end fashion. Meanwhile, continuous efforts are devoted to improvingthe quality of 3D mesh labels for a wide range of datasets. Though remarkableprogress has been achieved in the past decade, the task is still challengingdue to flexible body motions, diverse appearances, complex environments, andinsufficient in-the-wild annotations. To the best of our knowledge, this is thefirst survey to focus on the task of monocular 3D human mesh recovery. We startwith the introduction of body models, and then introduce recovery frameworksand training objectives by providing in-depth analyses of their strengths andweaknesses. We also summarize datasets, evaluation metrics, and benchmarkresults. Open issues and future directions are discussed in the end, hoping tomotivate researchers and facilitate their research in this area. A regularlyupdated project page can be found at this https URL.    ",2022/03/03,Computer Vision,54,
3,VisionLanguage Intelligence Tasks Representation Learning and Large Models,Feng Li Hao Zhang YiFan Zhang Shilong Liu Jian Guo Lionel M Ni PengChuan Zhang Lei Zhang,Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Computation and Language (cs.CL),"  This paper presents a comprehensive survey of vision-language (VL)intelligence from the perspective of time. This survey is inspired by theremarkable progress in both computer vision and natural language processing,and recent trends shifting from single modality processing to multiple modalitycomprehension. We summarize the development in this field into three timeperiods, namely task-specific methods, vision-language pre-training (VLP)methods, and larger models empowered by large-scale weakly-labeled data. Wefirst take some common VL tasks as examples to introduce the development oftask-specific methods. Then we focus on VLP methods and comprehensively reviewkey components of the model structures and training methods. After that, weshow how recent work utilizes large-scale raw image-text data to learnlanguage-aligned visual representations that generalize better on zero or fewshot learning tasks. Finally, we discuss some potential future trends towardsmodality cooperation, unified representation, and knowledge incorporation. Webelieve that this review will be of help for researchers and practitioners ofAI and ML, especially those interested in computer vision and natural languageprocessing.    ",2022/03/03,Computer Vision,12,
4,Playable Environments Video Manipulation in Space and Time,Willi Menapace Aliaksandr Siarohin Christian Theobalt Vladislav Golyanik Sergey Tulyakov Stéphane Lathuilière Elisa Ricci,Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI),"  We present Playable Environments - a new representation for interactive videogeneration and manipulation in space and time. With a single image at inferencetime, our novel framework allows the user to move objects in 3D whilegenerating a video by providing a sequence of desired actions. The actions arelearnt in an unsupervised manner. The camera can be controlled to get thedesired viewpoint. Our method builds an environment state for each frame, whichcan be manipulated by our proposed action module and decoded back to the imagespace with volumetric rendering. To support diverse appearances of objects, weextend neural radiance fields with style-based modulation. Our method trains ona collection of various monocular videos requiring only the estimated cameraparameters and 2D object locations. To set a challenging benchmark, weintroduce two large scale video datasets with significant camera movements. Asevidenced by our experiments, playable environments enable several creativeapplications not attainable by prior video synthesis works, including playable3D video generation, stylization and manipulation. Further details, code andexamples are available atthis https URL",2022/03/03,Computer Vision,72,
5,Instance Segmentation for Autonomous Log Grasping in Forestry Operations,JeanMichel Fortin Olivier Gamache Vincent Grondin François Pomerleau Philippe Giguère,Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO),"  Wood logs picking is a challenging task to automate. Indeed, logs usuallycome in cluttered configurations, randomly orientated and overlapping. Recentwork on log picking automation usually assume that the logs' pose is known,with little consideration given to the actual perception problem. In thispaper, we squarely address the latter, using a data-driven approach. First, weintroduce a novel dataset, named TimberSeg 1.0, that is densely annotated,i.e., that includes both bounding boxes and pixel-level mask annotations forlogs. This dataset comprises 220 images with 2500 individually segmented logs.Using our dataset, we then compare three neural network architectures on thetask of individual logs detection and segmentation; two region-based methodsand one attention-based method. Unsurprisingly, our results show thataxis-aligned proposals, failing to take into account the directional nature oflogs, underperform with 19.03 mAP. A rotation-aware proposal methodsignificantly improve results to 31.83 mAP. More interestingly, aTransformer-based approach, without any inductive bias on rotations,outperformed the two others, achieving a mAP of 57.53 on our dataset. Our usecase demonstrates the limitations of region-based approaches for cluttered,elongated objects. It also highlights the potential of attention-based methodson this specific task, as they work directly at the pixel-level. Theseencouraging results indicate that such a perception system could be used toassist the operators on the short-term, or to fully automate log pickingoperations in the future.    ",2022/03/03,Computer Vision,92,
6,TCTrack Temporal Contexts for Aerial Tracking,Ziang Cao Ziyuan Huang Liang Pan Shiwei Zhang Ziwei Liu Changhong Fu,Computer Vision and Pattern Recognition (cs.CV),"  Temporal contexts among consecutive frames are far from been fully utilizedin existing visual trackers. In this work, we present TCTrack, a comprehensiveframework to fully exploit temporal contexts for aerial tracking. The temporalcontexts are incorporated at \textbf{two levels}: the extraction of\textbf{features} and the refinement of \textbf{similarity maps}. Specifically,for feature extraction, an online temporally adaptive convolution is proposedto enhance the spatial features using temporal information, which is achievedby dynamically calibrating the convolution weights according to the previousframes. For similarity map refinement, we propose an adaptive temporaltransformer, which first effectively encodes temporal knowledge in amemory-efficient way, before the temporal knowledge is decoded for accurateadjustment of the similarity map. TCTrack is effective and efficient:evaluation on four aerial tracking benchmarks shows its impressive performance;real-world UAV tests show its high speed of over 27 FPS on NVIDIA Jetson AGXXavier.    ",2022/03/03,Computer Vision,126,
7,LatentFormer MultiAgent TransformerBased Interaction Modeling and Trajectory Prediction,Elmira Amirloo Amir Rasouli Peter Lakner Mohsen Rohani Jun Luo,Computer Vision and Pattern Recognition (cs.CV),"  Multi-agent trajectory prediction is a fundamental problem in autonomousdriving. The key challenges in prediction are accurately anticipating thebehavior of surrounding agents and understanding the scene context. To addressthese problems, we propose LatentFormer, a transformer-based model forpredicting future vehicle trajectories. The proposed method leverages a noveltechnique for modeling interactions among dynamic objects in the scene.Contrary to many existing approaches which model cross-agent interactionsduring the observation time, our method additionally exploits the future statesof the agents. This is accomplished using a hierarchical attention mechanismwhere the evolving states of the agents autoregressively control thecontributions of past trajectories and scene encodings in the final prediction.Furthermore, we propose a multi-resolution map encoding scheme that relies on avision transformer module to effectively capture both local and global scenecontext to guide the generation of more admissible future trajectories. Weevaluate the proposed method on the nuScenes benchmark dataset and show thatour approach achieves state-of-the-art performance and improves upon trajectorymetrics by up to 40%. We further investigate the contributions of variouscomponents of the proposed technique via extensive ablation studies.    ",2022/03/03,Computer Vision,138,
8,A study on the distribution of social biases in selfsupervised learning visual models,Kirill Sirotkin Pablo Carballeira Marcos EscuderoViñolo,Computer Vision and Pattern Recognition (cs.CV),"  Deep neural networks are efficient at learning the data distribution if it issufficiently sampled. However, they can be strongly biased by non-relevantfactors implicitly incorporated in the training data. These include operationalbiases, such as ineffective or uneven data sampling, but also ethical concerns,as the social biases are implicitly present\textemdash even inadvertently, inthe training data or explicitly defined in unfair training schedules. In taskshaving impact on human processes, the learning of social biases may producediscriminatory, unethical and untrustworthy consequences. It is often assumedthat social biases stem from supervised learning on labelled data, and thus,Self-Supervised Learning (SSL) wrongly appears as an efficient and bias-freesolution, as it does not require labelled data. However, it was recently proventhat a popular SSL method also incorporates biases. In this paper, we study thebiases of a varied set of SSL visual models, trained using ImageNet data, usinga method and dataset designed by psychological experts to measure socialbiases. We show that there is a correlation between the type of the SSL modeland the number of biases that it incorporates. Furthermore, the results alsosuggest that this number does not strictly depend on the model's accuracy andchanges throughout the network. Finally, we conclude that a careful SSL modelselection process can reduce the number of social biases in the deployed model,whilst keeping high performance.    ",2022/03/03,Computer Vision,19,
9,Efficient Video Instance Segmentation via Tracklet Query and Proposal,Jialian Wu Sudhir Yarram Hui Liang Tian Lan Junsong Yuan Jayan Eledath Gerard Medioni,Computer Vision and Pattern Recognition (cs.CV),"  Video Instance Segmentation (VIS) aims to simultaneously classify, segment,and track multiple object instances in videos. Recent clip-level VIS takes ashort video clip as input each time showing stronger performance thanframe-level VIS (tracking-by-segmentation), as more temporal context frommultiple frames is utilized. Yet, most clip-level methods are neitherend-to-end learnable nor real-time. These limitations are addressed by therecent VIS transformer (VisTR) which performs VIS end-to-end within a clip.However, VisTR suffers from long training time due to its frame-wise denseattention. In addition, VisTR is not fully end-to-end learnable in multiplevideo clips as it requires a hand-crafted data association to link instancetracklets between successive clips. This paper proposes EfficientVIS, a fullyend-to-end framework with efficient training and inference. At the core aretracklet query and tracklet proposal that associate and segmentregions-of-interest (RoIs) across space and time by an iterative query-videointeraction. We further propose a correspondence learning that makes trackletslinking between clips end-to-end learnable. Compared to VisTR, EfficientVISrequires 15x fewer training epochs while achieving state-of-the-art accuracy onthe YouTube-VIS benchmark. Meanwhile, our method enables whole video instancesegmentation in a single end-to-end pass without data association at all.    ",2022/03/03,Computer Vision,78,
10,STUN SelfTeaching Uncertainty Estimation for Place Recognition,Kaiwen Cai Chris Xiaoxuan Lu Xiaowei Huang,Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO),"  Place recognition is key to Simultaneous Localization and Mapping (SLAM) andspatial perception. However, a place recognition in the wild often suffers fromerroneous predictions due to image variations, e.g., changing viewpoints andstreet appearance. Integrating uncertainty estimation into the life cycle ofplace recognition is a promising method to mitigate the impact of variations onplace recognition performance. However, existing uncertainty estimationapproaches in this vein are either computationally inefficient (e.g., MonteCarlo dropout) or at the cost of dropped accuracy. This paper proposes STUN, aself-teaching framework that learns to simultaneously predict the place andestimate the prediction uncertainty given an input image. To this end, we firsttrain a teacher net using a standard metric learning pipeline to produceembedding priors. Then, supervised by the pretrained teacher net, a student netwith an additional variance branch is trained to finetune the embedding priorsand estimate the uncertainty sample by sample. During the online inferencephase, we only use the student net to generate a place prediction inconjunction with the uncertainty. When compared with place recognition systemsthat are ignorant to the uncertainty, our framework features the uncertaintyestimation for free without sacrificing any prediction accuracy. Ourexperimental results on the large-scale Pittsburgh30k dataset demonstrate thatSTUN outperforms the state-of-the-art methods in both recognition accuracy andthe quality of uncertainty estimation.    ",2022/03/03,Computer Vision,95,
11,LGTNet Indoor Panoramic Room Layout Estimation with GeometryAware Transformer Network,Zhigang Jiang Zhongzheng Xiang Jinhua Xu Ming Zhao,Computer Vision and Pattern Recognition (cs.CV),"  3D room layout estimation by a single panorama using deep neural networks hasmade great progress. However, previous approaches can not obtain efficientgeometry awareness of room layout with the only latitude of boundaries orhorizon-depth. We present that using horizon-depth along with room height canobtain omnidirectional-geometry awareness of room layout in both horizontal andvertical directions. In addition, we propose a planar-geometry aware lossfunction with normals and gradients of normals to supervise the planeness ofwalls and turning of corners. We propose an efficient network, LGT-Net, forroom layout estimation, which contains a novel Transformer architecture calledSWG Transformer to model geometry relations. SWG Transformer consists of(Shifted) Window Blocks and Global Blocks to combine the local and globalgeometry relations. Moreover, we design a novel relative position embedding ofTransformer to enhance the spatial identification ability for the panorama.Experiments show that the proposed LGT-Net achieves better performance thancurrent state-of-the-arts (SOTA) on benchmark datasets.    ",2022/03/03,Computer Vision,18,
12,Adaptive LocalGlobal Relational Network for Facial Action Units Recognition and Facial Paralysis Estimation,Xuri Ge Joemon M Jose Pengcheng Wang Arunachalam Iyer Xiao Liu Hu Han,Computer Vision and Pattern Recognition (cs.CV),"  Facial action units (AUs) refer to a unique set of facial muscle movements atcertain facial locations defined by the Facial Action Coding System (FACS),which can be used for describing nearly any anatomically possible facialexpression. Many existing facial action units (AUs) recognition approachesoften enhance the AU representation by combining local features from multipleindependent branches, each corresponding to a different AU, which usuallyneglect potential mutual assistance and exclusion relationship between AUbranches or simply employ a pre-defined and fixed knowledge-graph as a prior.In addition, extracting features from pre-defined AU regions of regular shapeslimits the representation ability. In this paper, we propose a novel AdaptiveLocal-Global Relational Network (ALGRNet) for facial AU recognition and applyit to facial paralysis estimation. ALGRNet mainly consists of three novelstructures, i.e., an adaptive region learning module which learns the adaptivemuscle regions based on the detected landmarks, a skip-BiLSTM module whichmodels the latent mutual assistance and exclusion relationship among local AUfeatures, and a feature fusion\&refining module which explores thecomplementarity between local AUs and the whole face for the local AUrefinement. In order to evaluate our proposed method, we migrated ALGRNet to afacial paralysis dataset which is collected and annotated by medicalprofessionals. Experiments on the BP4D and DISFA AU datasets show that theproposed approach outperforms the state-of-the-art methods by a large margin.Additionally, we also demonstrated the effectiveness of the proposed ALGRNet inapplications to facial paralysis estimation.    ",2022/03/03,Computer Vision,45,
13,Revisiting Clickbased Interactive Video Object Segmentation,Stephane Vujasinovic Sebastian Bullinger Stefan Becker Norbert SchererNegenborn Michael Arens Rainer Stiefelhagen,Computer Vision and Pattern Recognition (cs.CV),"  While current methods for interactive Video Object Segmentation (iVOS) relyon scribble-based interactions to generate precise object masks, we propose aClick-based interactive Video Object Segmentation (CiVOS) framework to simplifythe required user workload as much as possible. CiVOS builds on de-coupledmodules reflecting user interaction and mask propagation. The interactionmodule converts click-based interactions into an object mask, which is theninferred to the remaining frames by the propagation module. Additional userinteractions allow for a refinement of the object mask. The approach isextensively evaluated on the popular interactive~DAVIS dataset, but with aninevitable adaptation of scribble-based interactions with click-basedcounterparts. We consider several strategies for generating clicks during ourevaluation to reflect various user inputs and adjust the DAVIS performancemetric to perform a hardware-independent comparison. The presented CiVOSpipeline achieves competitive results, although requiring a lower userworkload.    ",2022/03/03,Computer Vision,71,
14,PINA Learning a Personalized Implicit Neural Avatar from a Single RGBD Video Sequence,Zijian Dong Chen Guo Jie Song Xu Chen Andreas Geiger Otmar Hilliges,Computer Vision and Pattern Recognition (cs.CV),"  We present a novel method to learn Personalized Implicit Neural Avatars(PINA) from a short RGB-D sequence. This allows non-expert users to create adetailed and personalized virtual copy of themselves, which can be animatedwith realistic clothing deformations. PINA does not require complete scans, nordoes it require a prior learned from large datasets of clothed humans. Learninga complete avatar in this setting is challenging, since only few depthobservations are available, which are noisy and incomplete (i.e.only partialvisibility of the body per frame). We propose a method to learn the shape andnon-rigid deformations via a pose-conditioned implicit surface and adeformation field, defined in canonical space. This allows us to fuse allpartial observations into a single consistent canonical representation. Fusionis formulated as a global optimization problem over the pose, shape andskinning parameters. The method can learn neural avatars from real noisy RGB-Dsequences for a diverse set of people and clothing styles and these avatars canbe animated given unseen motion sequences.    ",2022/03/03,Computer Vision,4,
15,ModalityAdaptive Mixup and Invariant Decomposition for RGBInfrared Person ReIdentification,Zhipeng Huang Jiawei Liu Liang Li Kecheng Zheng ZhengJun Zha,Computer Vision and Pattern Recognition (cs.CV),"  RGB-infrared person re-identification is an emerging cross-modalityre-identification task, which is very challenging due to significant modalitydiscrepancy between RGB and infrared images. In this work, we propose a novelmodality-adaptive mixup and invariant decomposition (MID) approach forRGB-infrared person re-identification towards learning modality-invariant anddiscriminative representations. MID designs a modality-adaptive mixup scheme togenerate suitable mixed modality images between RGB and infrared images formitigating the inherent modality discrepancy at the pixel-level. It formulatesmodality mixup procedure as Markov decision process, where an actor-criticagent learns dynamical and local linear interpolation policy between differentregions of cross-modality images under a deep reinforcement learning framework.Such policy guarantees modality-invariance in a more continuous latent spaceand avoids manifold intrusion by the corrupted mixed modality samples.Moreover, to further counter modality discrepancy and enforce invariant visualsemantics at the feature-level, MID employs modality-adaptive convolutiondecomposition to disassemble a regular convolution layer into modality-specificbasis layers and a modality-shared coefficient layer. Extensive experimentalresults on two challenging benchmarks demonstrate superior performance of MIDover state-of-the-art methods.    ",2022/03/03,Computer Vision,2,
16,Beyond 3D Siamese Tracking A MotionCentric Paradigm for 3D Single Object Tracking in Point Clouds,Chaoda Zheng Xu Yan Haiming Zhang Baoyuan Wang Shenghui Cheng Shuguang Cui Zhen Li,Computer Vision and Pattern Recognition (cs.CV),"  3D single object tracking (3D SOT) in LiDAR point clouds plays a crucial rolein autonomous driving. Current approaches all follow the Siamese paradigm basedon appearance matching. However, LiDAR point clouds are usually textureless andincomplete, which hinders effective appearance matching. Besides, previousmethods greatly overlook the critical motion clues among targets. In this work,beyond 3D Siamese tracking, we introduce a motion-centric paradigm to handle 3DSOT from a new perspective. Following this paradigm, we propose a matching-freetwo-stage tracker M^2-Track. At the 1^st-stage, M^2-Track localizes the targetwithin successive frames via motion transformation. Then it refines the targetbox through motion-assisted shape completion at the 2^nd-stage. Extensiveexperiments confirm that M^2-Track significantly outperforms previousstate-of-the-arts on three large-scale datasets while running at 57FPS (~8%,~17%, and ~22%) precision gains on KITTI, NuScenes, and Waymo Open Datasetrespectively). Further analysis verifies each component's effectiveness andshows the motion-centric paradigm's promising potential when combined withappearance matching.    ",2022/03/03,Computer Vision,53,
17,Ensembles of Vision Transformers as a New Paradigm for Automated Classification in Ecology,S Kyathanahally T Hardeman M Reyes E Merz T Bulas F Pomati M BaityJesi,Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG),"  Monitoring biodiversity is paramount to manage and protect natural resources,particularly in times of global change. Collecting images of organisms overlarge temporal or spatial scales is a promising practice to monitor and studybiodiversity change of natural ecosystems, providing large amounts of data withminimal interference with the environment. Deep learning models are currentlyused to automate classification of organisms into taxonomic units. However,imprecision in these classifiers introduce a measurement noise that isdifficult to control and can significantly hinder the analysis andinterpretation of data. In our study, we show that this limitation can beovercome by ensembles of Data-efficient image Transformers (DeiTs), whichsignificantly outperform the previous state of the art (SOTA). We validate ourresults on a large number of ecological imaging datasets of diverse origin, andorganisms of study ranging from plankton to insects, birds, dog breeds, animalsin the wild, and corals. On all the data sets we test, we achieve a new SOTA,with a reduction of the error with respect to the previous SOTA ranging from18.48% to 87.50%, depending on the data set, and often achieving performancesvery close to perfect classification. The main reason why ensembles of DeiTsperform better is not due to the single-model performance of DeiTs, but ratherto the fact that predictions by independent models have a smaller overlap, andthis maximizes the profit gained by ensembling. This positions DeiT ensemblesas the best candidate for image classification in biodiversity monitoring.    ",2022/03/03,Computer Vision,56,
18,Debiased Batch Normalization via Gaussian Process for Generalizable Person ReIdentification,Jiawei Liu Zhipeng Huang Liang Li Kecheng Zheng ZhengJun Zha,Computer Vision and Pattern Recognition (cs.CV),"  Generalizable person re-identification aims to learn a model with onlyseveral labeled source domains that can perform well on unseen domains. Withoutaccess to the unseen domain, the feature statistics of the batch normalization(BN) layer learned from a limited number of source domains is doubtlesslybiased for unseen domain. This would mislead the feature representationlearning for unseen domain and deteriorate the generalizaiton ability of themodel. In this paper, we propose a novel Debiased Batch Normalization viaGaussian Process approach (GDNorm) for generalizable person re-identification,which models the feature statistic estimation from BN layers as a dynamicallyself-refining Gaussian process to alleviate the bias to unseen domain forimproving the generalization. Specifically, we establish a lightweight modelwith multiple set of domain-specific BN layers to capture the discriminabilityof individual source domain, and learn the corresponding parameters of thedomain-specific BN layers. These parameters of different source domains areemployed to deduce a Gaussian process. We randomly sample several paths fromthis Gaussian process served as the BN estimations of potential new domainsoutside of existing source domains, which can further optimize these learnedparameters from source domains, and estimate more accurate Gaussian process bythem in return, tending to real data distribution. Even without a large numberof source domains, GDNorm can still provide debiased BN estimation by using themean path of the Gaussian process, while maintaining low computational costduring testing. Extensive experiments demonstrate that our GDNorm effectivelyimproves the generalization ability of the model on unseen domain.    ",2022/03/03,Computer Vision,61,
19,Weakly Supervised Object Localization as Domain Adaption,Lei Zhu Qi She Qian Chen Yunfei You Boyu Wang Yanye Lu,Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG),"  Weakly supervised object localization (WSOL) focuses on localizing objectsonly with the supervision of image-level classification masks. Most previousWSOL methods follow the classification activation map (CAM) that localizesobjects based on the classification structure with the multi-instance learning(MIL) mechanism. However, the MIL mechanism makes CAM only activatediscriminative object parts rather than the whole object, weakening itsperformance for localizing objects. To avoid this problem, this work provides anovel perspective that models WSOL as a domain adaption (DA) task, where thescore estimator trained on the source/image domain is tested on thetarget/pixel domain to locate objects. Under this perspective, a DA-WSOLpipeline is designed to better engage DA approaches into WSOL to enhancelocalization performance. It utilizes a proposed target sampling strategy toselect different types of target samples. Based on these types of targetsamples, domain adaption localization (DAL) loss is elaborated. It aligns thefeature distribution between the two domains by DA and makes the estimatorperceive target domain cues by Universum regularization. Experiments show thatour pipeline outperforms SOTA methods on multi benchmarks. Code are released at\url{this https URL}.    ",2022/03/03,Computer Vision,138,
20,Capturing Shape Information with MultiScale Topological Loss Terms for 3D Reconstruction,Dominik J E Waibel Scott Atwell Matthias Meier Carsten Marr Bastian Rieck,Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Image and Video Processing (eess.IV); Machine Learning (stat.ML),"  Reconstructing 3D objects from 2D images is both challenging for our brainsand machine learning algorithms. To support this spatial reasoning task,contextual information about the overall shape of an object is critical.However, such information is not captured by established loss terms (e.g. Diceloss). We propose to complement geometrical shape information by includingmulti-scale topological features, such as connected components, cycles, andvoids, in the reconstruction loss. Our method calculates topological featuresfrom 3D volumetric data based on cubical complexes and uses an optimaltransport distance to guide the reconstruction process. This topology-awareloss is fully differentiable, computationally efficient, and can be added toany neural network. We demonstrate the utility of our loss by incorporating itinto SHAPR, a model for predicting the 3D cell shape of individual cells basedon 2D microscopy images. Using a hybrid loss that leverages both geometricaland topological information of single objects to assess their shape, we findthat topological information substantially improves the quality ofreconstructions, thus highlighting its ability to extract more relevantfeatures from image datasets.    ",2022/03/03,Computer Vision,131,
21,Relative distance matters for oneshot landmark detection,Qingsong Yao Jianji Wang Yihua Sun Quan Quan Heqin Zhu S Kevin Zhou,Computer Vision and Pattern Recognition (cs.CV),"  Contrastive learning based methods such as cascade comparing to detect (CC2D)have shown great potential for one-shot medical landmark detection. However,the important cue of relative distance between landmarks is ignored in CC2D. Inthis paper, we upgrade CC2D to version II by incorporating asimple-yet-effective relative distance bias in the training stage, which istheoretically proved to encourage the encoder to project the relatively distantlandmarks to the embeddings with low similarities. As consequence, CC2Dv2 isless possible to detect a wrong point far from the correct landmark.Furthermore, we present an open-source, landmark-labeled dataset for themeasurement of biomechanical parameters of the lower extremity to alleviate theburden of orthopedic surgeons. The effectiveness of CC2Dv2 is evaluated on thepublic dataset from the ISBI 2015 Grand-Challenge of cephalometric radiographsand our new dataset, which greatly outperforms the state-of-the-art one-shotlandmark detection approaches.    ",2022/03/03,Computer Vision,89,
22,Bridging the Sourcetotarget Gap for Crossdomain Person ReIdentification with Intermediate Domains,Yongxing Dai Yifan Sun Jun Liu Zekun Tong Yi Yang LingYu Duan,Computer Vision and Pattern Recognition (cs.CV),"  Cross-domain person re-identification (re-ID), such as unsupervised domainadaptive (UDA) re-ID, aims to transfer the identity-discriminative knowledgefrom the source to the target domain. Existing methods commonly consider thesource and target domains are isolated from each other, i.e., no intermediatestatus is modeled between both domains. Directly transferring the knowledgebetween two isolated domains can be very difficult, especially when the domaingap is large. From a novel perspective, we assume these two domains are notcompletely isolated, but can be connected through intermediate domains. Insteadof directly aligning the source and target domains against each other, wepropose to align the source and target domains against their intermediatedomains for a smooth knowledge transfer. To discover and utilize theseintermediate domains, we propose an Intermediate Domain Module (IDM) and aMirrors Generation Module (MGM). IDM has two functions: 1) it generatesmultiple intermediate domains by mixing the hidden-layer features from sourceand target domains and 2) it dynamically reduces the domain gap between thesource / target domain features and the intermediate domain features. While IDMachieves good domain alignment, it introduces a side effect, i.e., the mix-upoperation may mix the identities into a new identity and lose the originalidentities. To compensate this, MGM is introduced by mapping the features intothe IDM-generated intermediate domains without changing their originalidentity. It allows to focus on minimizing domain variations to promote thealignment between the source / target domain and intermediate domains, whichreinforces IDM into IDM++. We extensively evaluate our method under both theUDA and domain generalization (DG) scenarios and observe that IDM++ yieldsconsistent performance improvement for cross-domain re-ID, achieving new stateof the art.    ",2022/03/03,Computer Vision,17,
23,CrossModality Earth Movers Distance for Visible Thermal Person ReIdentification,Yongguo Ling Zhun Zhong Donglin Cao Zhiming Luo Yaojin Lin Shaozi Li Nicu Sebe,Computer Vision and Pattern Recognition (cs.CV),"  Visible thermal person re-identification (VT-ReID) suffers from theinter-modality discrepancy and intra-identity variations. Distributionalignment is a popular solution for VT-ReID, which, however, is usuallyrestricted to the influence of the intra-identity variations. In this paper, wepropose the Cross-Modality Earth Mover's Distance (CM-EMD) that can alleviatethe impact of the intra-identity variations during modality alignment. CM-EMDselects an optimal transport strategy and assigns high weights to pairs thathave a smaller intra-identity variation. In this manner, the model will focuson reducing the inter-modality discrepancy while paying less attention tointra-identity variations, leading to a more effective modality alignment.Moreover, we introduce two techniques to improve the advantage of CM-EMD.First, the Cross-Modality Discrimination Learning (CM-DL) is designed toovercome the discrimination degradation problem caused by modality alignment.By reducing the ratio between intra-identity and inter-identity variances,CM-DL leads the model to learn more discriminative representations. Second, weconstruct the Multi-Granularity Structure (MGS), enabling us to alignmodalities from both coarse- and fine-grained levels with the proposed CM-EMD.Extensive experiments show the benefits of the proposed CM-EMD and itsauxiliary techniques (CM-DL and MGS). Our method achieves state-of-the-artperformance on two VT-ReID benchmarks.    ",2022/03/03,Computer Vision,128,
24,CorrelationAware Deep Tracking,Fei Xie Chunyu Wang Guangting Wang Yue Cao Wankou Yang Wenjun Zeng,Computer Vision and Pattern Recognition (cs.CV),"  Robustness and discrimination power are two fundamental requirements invisual object tracking. In most tracking paradigms, we find that the featuresextracted by the popular Siamese-like networks cannot fully discriminativelymodel the tracked targets and distractor objects, hindering them fromsimultaneously meeting these two requirements. While most methods focus ondesigning robust correlation operations, we propose a novel target-dependentfeature network inspired by the self-/cross-attention scheme. In contrast tothe Siamese-like feature extraction, our network deeply embeds cross-imagefeature correlation in multiple layers of the feature network. By extensivelymatching the features of the two images through multiple layers, it is able tosuppress non-target features, resulting in instance-varying feature extraction.The output features of the search image can be directly used for predictingtarget locations without extra correlation step. Moreover, our model can beflexibly pre-trained on abundant unpaired images, leading to notably fasterconvergence than the existing methods. Extensive experiments show our methodachieves the state-of-the-art results while running at real-time. Our featurenetworks also can be applied to existing tracking pipelines seamlessly to raisethe tracking performance. Code will be available.    ",2022/03/03,Computer Vision,57,
25,Adaptive Path Planning for UAVs for MultiResolution Semantic Segmentation,Felix Stache Jonas Westheider Federico Magistri Cyrill Stachniss Marija Popović,Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO),"  Efficient data collection methods play a major role in helping us betterunderstand the Earth and its ecosystems. In many applications, the usage ofunmanned aerial vehicles (UAVs) for monitoring and remote sensing is rapidlygaining momentum due to their high mobility, low cost, and flexible deployment.A key challenge is planning missions to maximize the value of acquired data inlarge environments given flight time limitations. This is, for example,relevant for monitoring agricultural fields. This paper addresses the problemof adaptive path planning for accurate semantic segmentation of using UAVs. Wepropose an online planning algorithm which adapts the UAV paths to obtainhigh-resolution semantic segmentations necessary in areas with fine details asthey are detected in incoming images. This enables us to perform closeinspections at low altitudes only where required, without wasting energy onexhaustive mapping at maximum image resolution. A key feature of our approachis a new accuracy model for deep learning-based architectures that captures therelationship between UAV altitude and semantic segmentation accuracy. Weevaluate our approach on different domains using real-world data, proving theefficacy and generability of our solution.    ",2022/03/03,Computer Vision,54,
26,Improved Approximation Algorithms and Lower Bounds for SearchDiversification Problems,Amir Abboud Vincent CohenAddad Euiwoong Lee Pasin Manurangsi,Data Structures and Algorithms (cs.DS),"  We study several questions related to diversifying search results. We giveimproved approximation algorithms in each of the following problems, togetherwith some lower bounds.- We give a polynomial-time approximation scheme (PTAS) for a diversifiedsearch ranking problem [Bansal et al., ICALP 2010] whose objective is tominimizes the discounted cumulative gain. Our PTAS runs in time$n^{2^{O(\log(1/\epsilon)/\epsilon)}} \cdot m^{O(1)}$ where $n$ denotes thenumber of elements in the databases. Complementing this, we show that no PTAScan run in time $f(\epsilon) \cdot (nm)^{2^{o(1/\epsilon)}}$ assuming Gap-ETH;therefore our running time is nearly tight. Both of our bounds answer openquestions of Bansal et al.- We next consider the Max-Sum Dispersion problem, whose objective is toselect $k$ out of $n$ elements that maximizes the dispersion, which is definedas the sum of the pairwise distances under a given metric. We give aquasipolynomial-time approximation scheme for the problem which runs in time$n^{O_{\epsilon}(\log n)}$. This improves upon previously known polynomial-timealgorithms with approximate ratios 0.5 [Hassin et al., Oper. Res. Lett. 1997;Borodin et al., ACM Trans. Algorithms 2017]. Furthermore, we observe that knownreductions rule out approximation schemes that run in$n^{\tilde{o}_\epsilon(\log n)}$ time assuming ETH.- We consider a generalization of Max-Sum Dispersion called Max-SumDiversification. In addition to the sum of pairwise distance, the objectiveincludes another function $f$. For monotone submodular $f$, we give aquasipolynomial-time algorithm with approximation ratio arbitrarily close to$(1 - 1/e)$. This improves upon the best polynomial-time algorithm which hasapproximation ratio $0.5$ by Borodin et al. Furthermore, the $(1 - 1/e)$ factoris tight as achieving better-than-$(1 - 1/e)$ approximation is NP-hard [Feige,J. ACM 1998].    ",2022/03/03,Data Structures,62,
27,High Multiplicity Scheduling on Uniform Machines in FPTTime,Hauke Brinkop Klaus Jansen,Data Structures and Algorithms (cs.DS),"  In high-multiplicity scheduling, jobs of the same size are encoded in anefficient way, that is, for each size the number of jobs of that size is giveninstead of a list of jobs. Similarly, machines are encoded. We considerscheduling on uniform machines where a job of size $p_j$ takes time $p_j/s_i$on a machine of speed $s_i$. Classical (NP-hard) objectives are Makespanminimization ($C_{\max}$) and Santa Claus ($C_{\min}$). We show that bothobjectives can be solved in time $\mathcal O( p_{\max}^{\mathcal O(d^2)}\operatorname {poly} |I| )$ where $p_{\max}$ is the largest jobs size, $d$ thenumber of different job sizes and $|I|$ the encoding length of the instance.Our approach incorporates two structural theorems: The first allows us toreplace machines of large speed by multiple machines of smaller speed. Thesecond tells us that some fractional assignments can be used to reduce theinstance significantly. Using only the first theorem, we show some additionalresults. For the problem Envy Minimization ($C_{\mathit{envy}}$), we propose an$\mathcal O(s_{\max} \cdot p_{\max}^{\mathcal O(d^3)} \operatorname{poly} |I|)$time algorithm (where $s_{\max}$ is the largest speed). For $C_{\max}$ and$C_{\min}$ in the Restricted Assignment setting, we give an $\mathcal O( (dp_{\max})^{\mathcal O(d^3)} \operatorname{poly} |I|)$ time algorithm. As far aswe know, those running times are better than the running times of thealgorithms known until today.    ",2022/03/03,Data Structures,97,
28,A Formalisation of Algorithms for Sorting Network,Laurent Théry STAMP,Data Structures and Algorithms (cs.DS),This notes explains how standard algorithms that construct sorting networkshave been formalised and proved correct in the Coq proof assistant using theSSReflect extension.,2022/03/03,Data Structures,32,
29,Private HighDimensional Hypothesis Testing,Shyam Narayanan,Data Structures and Algorithms (cs.DS); Cryptography and Security (cs.CR); Information Theory (cs.IT); Machine Learning (cs.LG); Statistics Theory (math.ST),"  We provide improved differentially private algorithms for identity testing ofhigh-dimensional distributions. Specifically, for $d$-dimensional Gaussiandistributions with known covariance $\Sigma$, we can test whether thedistribution comes from $\mathcal{N}(\mu^*, \Sigma)$ for some fixed $\mu^*$ orfrom some $\mathcal{N}(\mu, \Sigma)$ with total variation distance at least$\alpha$ from $\mathcal{N}(\mu^*, \Sigma)$ with $(\varepsilon, 0)$-differentialprivacy, using only \[\tilde{O}\left(\frac{d^{1/2}}{\alpha^2} +\frac{d^{1/3}}{\alpha^{4/3} \cdot \varepsilon^{2/3}} + \frac{1}{\alpha \cdot\varepsilon}\right)\] samples if the algorithm is allowed to be computationallyinefficient, and only \[\tilde{O}\left(\frac{d^{1/2}}{\alpha^2} +\frac{d^{1/4}}{\alpha \cdot \varepsilon}\right)\] samples for a computationallyefficient algorithm. We also provide a matching lower bound showing that ourcomputationally inefficient algorithm has optimal sample complexity. We alsoextend our algorithms to various related problems, including mean testing ofGaussians with bounded but unknown covariance, uniformity testing of productdistributions over $\{\pm 1\}^d$, and tolerant testing.Our results improve over the previous best work of Canonne, Kamath, McMillan,Ullman, and Zakynthinou \cite{CanonneKMUZ20} for both computationally efficientand inefficient algorithms, and even our computationally efficient algorithmmatches the optimal \emph{non-private} sample complexity of$O\left(\frac{\sqrt{d}}{\alpha^2}\right)$ in many standard parameter settings.In addition, our results show that, surprisingly, private identity testing of$d$-dimensional Gaussians can be done with fewer samples than private identitytesting of discrete distributions over a domain of size $d$ \cite{AcharyaSZ18},which refutes a conjectured lower bound of Canonne et al. \cite{CanonneKMUZ20}.    ",2022/03/03,Data Structures,56,
30,Uniform Approximations for Randomized Hadamard Transforms with Applications,Yeshwanth Cherapanamjeri Jelani Nelson,Machine Learning (cs.LG); Computational Geometry (cs.CG); Data Structures and Algorithms (cs.DS); Machine Learning (stat.ML),"  Randomized Hadamard Transforms (RHTs) have emerged as a computationallyefficient alternative to the use of dense unstructured random matrices across arange of domains in computer science and machine learning. For severalapplications such as dimensionality reduction and compressed sensing, thetheoretical guarantees for methods based on RHTs are comparable to approachesusing dense random matrices with i.i.d.\ entries. However, several suchapplications are in the low-dimensional regime where the number of rows sampledfrom the matrix is rather small. Prior arguments are not applicable to thehigh-dimensional regime often found in machine learning applications likekernel approximation. Given an ensemble of RHTs with Gaussian diagonals,$\{M^i\}_{i = 1}^m$, and any $1$-Lipschitz function, $f: \mathbb{R} \to\mathbb{R}$, we prove that the average of $f$ over the entries of $\{M^i v\}_{i= 1}^m$ converges to its expectation uniformly over $\| v \| \leq 1$ at a ratecomparable to that obtained from using truly Gaussian matrices. We use ourinequality to then derive improved guarantees for two applications in thehigh-dimensional regime: 1) kernel approximation and 2) distance estimation.For kernel approximation, we prove the first \emph{uniform} approximationguarantees for random features constructed through RHTs lending theoreticaljustification to their empirical success while for distance estimation, ourconvergence result implies data structures with improved runtime guaranteesover previous work by the authors. We believe our general inequality is likelyto find use in other applications.    ",2022/03/03,Data Structures,14,
31,NearOptimal Correlation Clustering with Privacy,Vincent CohenAddad Chenglin Fan Silvio Lattanzi Slobodan Mitrović Ashkan NorouziFard Nikos Parotsidis Jakub Tarnawski,Machine Learning (cs.LG); Cryptography and Security (cs.CR); Data Structures and Algorithms (cs.DS),"  Correlation clustering is a central problem in unsupervised learning, withapplications spanning community detection, duplicate detection, automatedlabelling and many more. In the correlation clustering problem one receives asinput a set of nodes and for each node a list of co-clustering preferences, andthe goal is to output a clustering that minimizes the disagreement with thespecified nodes' preferences. In this paper, we introduce a simple andcomputationally efficient algorithm for the correlation clustering problem withprovable privacy guarantees. Our approximation guarantees are stronger thanthose shown in prior work and are optimal up to logarithmic factors.    ",2022/03/02,Data Structures,93,
32,Descending Price Auctions with Bounded Number of Price Levels and Batched Prophet Inequality,Saeed Alaei Ali Makhdoumi Azarakhsh Malekian Rad Niazadeh,Computer Science and Game Theory (cs.GT); Discrete Mathematics (cs.DM); Data Structures and Algorithms (cs.DS); Theoretical Economics (econ.TH),"  We consider descending price auctions for selling $m$ units of a good to unitdemand i.i.d. buyers where there is an exogenous bound of $k$ on the number ofprice levels the auction clock can take. The auctioneer's problem is to chooseprice levels $p_1 > p_2 > \cdots > p_{k}$ for the auction clock such thatauction expected revenue is maximized. The prices levels are announced prior tothe auction. We reduce this problem to a new variant of prophet inequality,which we call \emph{batched prophet inequality}, where a decision-maker chooses$k$ (decreasing) thresholds and then sequentially collects rewards (up to $m$)that are above the thresholds with ties broken uniformly at random. For thespecial case of $m=1$ (i.e., selling a single item), we show that the resultingdescending auction with $k$ price levels achieves $1- 1/e^k$ of theunrestricted (without the bound of $k$) optimal revenue. That means adescending auction with just 4 price levels can achieve more than 98\% of theoptimal revenue. We then extend our results for $m>1$ and provide a closed-formbound on the competitive ratio of our auction as a function of the number ofunits $m$ and the number of price levels $k$.    ",2022/03/02,Data Structures,59,
33,TCal An optimal test for the calibration of predictive models,Donghwan Lee Xinmeng Huang Hamed Hassani Edgar Dobriban,Machine Learning (stat.ML); Machine Learning (cs.LG),"  The prediction accuracy of machine learning methods is steadily increasing,but the calibration of their uncertainty predictions poses a significantchallenge. Numerous works focus on obtaining well-calibrated predictive models,but less is known about reliably assessing model calibration. This limits ourability to know when algorithms for improving calibration have a real effect,and when their improvements are merely artifacts due to random noise in finitedatasets. In this work, we consider detecting mis-calibration of predictivemodels using a finite validation dataset as a hypothesis testing problem. Thenull hypothesis is that the predictive model is calibrated, while thealternative hypothesis is that the deviation from calibration is sufficientlylarge.We find that detecting mis-calibration is only possible when the conditionalprobabilities of the classes are sufficiently smooth functions of thepredictions. When the conditional class probabilities are Hölder continuous,we propose T-Cal, a minimax optimal test for calibration based on a debiasedplug-in estimator of the $\ell_2$-Expected Calibration Error (ECE). We furtherpropose Adaptive T-Cal, a version that is adaptive to unknown smoothness. Weverify our theoretical findings with a broad range of experiments, includingwith several popular deep neural net architectures and several standardpost-hoc calibration methods. T-Cal is a practical general-purpose tool, which-- combined with classical tests for discrete-valued predictors -- can be usedto test the calibration of virtually any probabilistic classification method.    ",2022/03/03,Machine Learning,44,
34,Reinforcement Learning in Possibly Nonstationary Environments,Mengbing Li Chengchun Shi Zhenke Wu Piotr Fryzlewicz,Machine Learning (stat.ML); Machine Learning (cs.LG),"  We consider reinforcement learning (RL) methods in offline nonstationaryenvironments. Many existing RL algorithms in the literature rely on thestationarity assumption that requires the system transition and the rewardfunction to be constant over time. However, the stationarity assumption isrestrictive in practice and is likely to be violated in a number ofapplications, including traffic signal control, robotics and mobile health. Inthis paper, we develop a consistent procedure to test the nonstationarity ofthe optimal policy based on pre-collected historical data, without additionalonline data collection. Based on the proposed test, we further develop asequential change point detection method that can be naturally coupled withexisting state-of-the-art RL methods for policy optimisation in nonstationaryenvironments. The usefulness of our method is illustrated by theoreticalresults, simulation studies, and a real data example from the 2018 InternHealth Study. A Python implementation of the proposed procedure is available atthis https URL",2022/03/03,Machine Learning,138,
35,Estimating Conditional Average Treatment Effects with Missing Treatment Information,Milan Kuzmanovic Tobias Hatt Stefan Feuerriegel,Machine Learning (stat.ML); Machine Learning (cs.LG),"  Estimating conditional average treatment effects (CATE) is challenging,especially when treatment information is missing. Although this is a widespreadproblem in practice, CATE estimation with missing treatments has receivedlittle attention. In this paper, we analyze CATE estimation in the setting withmissing treatments where, thus, unique challenges arise in the form ofcovariate shifts. We identify two covariate shifts in our setting: (i) acovariate shift between the treated and control population; and (ii) acovariate shift between the observed and missing treatment population. We firsttheoretically show the effect of these covariate shifts by deriving ageneralization bound for estimating CATE in our setting with missingtreatments. Then, motivated by our bound, we develop the missing treatmentrepresentation network (MTRNet), a novel CATE estimation algorithm that learnsa balanced representation of covariates using domain adaptation. By usingbalanced representations, MTRNet provides more reliable CATE estimates in thecovariate domains where the data are not fully observed. In various experimentswith semi-synthetic and real-world data, we show that our algorithm improvesover the state-of-the-art by a substantial margin.    ",2022/03/02,Machine Learning,143,
36,Bayesian Spillover Graphs for Dynamic Networks,Grace Deng David S Matteson,Methodology (stat.ME); Machine Learning (cs.LG); Applications (stat.AP); Machine Learning (stat.ML),"  We present Bayesian Spillover Graphs (BSG), a novel method for learningtemporal relationships, identifying critical nodes, and quantifying uncertaintyfor multi-horizon spillover effects in a dynamic system. BSG leverages both aninterpretable framework via forecast error variance decompositions (FEVD) andcomprehensive uncertainty quantification via Bayesian time series models tocontextualize temporal relationships in terms of systemic risk and predictionvariability. Forecast horizon hyperparameter $h$ allows for learning bothshort-term and equilibrium state network behaviors. Experiments for identifyingsource and sink nodes under various graph and error specifications showsignificant performance gains against state-of-the-art Bayesian Networks anddeep-learning baselines. Applications to real-world systems also showcase BSGas an exploratory analysis tool for uncovering indirect spillovers andquantifying risk.    ",2022/03/03,Machine Learning,26,
37,Sparse Bayesian Optimization,Sulin Liu Qing Feng David Eriksson Benjamin Letham Eytan Bakshy,Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Optimization and Control (math.OC); Machine Learning (stat.ML),"  Bayesian optimization (BO) is a powerful approach to sample-efficientoptimization of black-box objective functions. However, the application of BOto areas such as recommendation systems often requires taking theinterpretability and simplicity of the configurations into consideration, asetting that has not been previously studied in the BO literature. To make BOapplicable in this setting, we present several regularization-based approachesthat allow us to discover sparse and more interpretable configurations. Wepropose a novel differentiable relaxation based on homotopy continuation thatmakes it possible to target sparsity by working directly with $L_0$regularization. We identify failure modes for regularized BO and develop ahyperparameter-free method, sparsity exploring Bayesian optimization (SEBO)that seeks to simultaneously maximize a target objective and sparsity. SEBO andmethods based on fixed regularization are evaluated on synthetic and real-worldproblems, and we show that we are able to efficiently optimize for sparsity.    ",2022/03/03,Machine Learning,101,
38,Identification in Treeshaped Linear Structural Causal Models,Benito van der Zander Marcel Wienöbst Markus Bläser Maciej Liśkiewicz,Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Symbolic Computation (cs.SC); Machine Learning (stat.ML),"  Linear structural equation models represent direct causal effects as directededges and confounding factors as bidirected edges. An open problem is toidentify the causal parameters from correlations between the nodes. Weinvestigate models, whose directed component forms a tree, and show that there,besides classical instrumental variables, missing cycles of bidirected edgescan be used to identify the model. They can yield systems of quadraticequations that we explicitly solve to obtain one or two solutions for thecausal parameters of adjacent directed edges. We show how multiple missingcycles can be combined to obtain a unique solution. This results in analgorithm that can identify instances that previously required approaches basedon Gröbner bases, which have doubly-exponential time complexity in the numberof structural parameters.    ",2022/03/03,Machine Learning,137,
39,Local ConstraintBased Causal Discovery under Selection Bias,Philip Versteeg Cheng Zhang Joris M Mooij,Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML),"  We consider the problem of discovering causal relations from independenceconstraints selection bias in addition to confounding is present. While theseminal FCI algorithm is sound and complete in this setup, no criterion for thecausal interpretation of its output under selection bias is presently known. Wefocus instead on local patterns of independence relations, where we find nosound method for only three variable that can include background knowledge.Y-Structure patterns are shown to be sound in predicting causal relations fromdata under selection bias, where cycles may be present. We introduce afinite-sample scoring rule for Y-Structures that is shown to successfullypredict causal relations in simulation experiments that include selectionmechanisms. On real-world microarray data, we show that a Y-Structure variantperforms well across different datasets, potentially circumventing spuriouscorrelations due to selection bias.    ",2022/03/03,Machine Learning,144,
40,Understanding microbiome dynamics via interpretable graph representation learning,Kateryna Melnyk Kuba Weimann Tim OF Conrad,Quantitative Methods (q-bio.QM); Machine Learning (cs.LG); Dynamical Systems (math.DS); Machine Learning (stat.ML),"  Large-scale perturbations in the microbiome constitution are stronglycorrelated, whether as a driver or a consequence, with the health andfunctioning of human physiology. However, understanding the difference in themicrobiome profiles of healthy and ill individuals can be complicated due tothe large number of complex interactions among microbes. We propose to modelthese interactions as a time-evolving graph whose nodes are microbes and edgesare interactions among them. Motivated by the need to analyse such complexinteractions, we develop a method that learns a low-dimensional representationof the time-evolving graph and maintains the dynamics occurring in thehigh-dimensional space. Through our experiments, we show that we can extractgraph features such as clusters of nodes or edges that have the highest impacton the model to learn the low-dimensional representation. This information canbe crucial to identify microbes and interactions among them that are stronglycorrelated with clinical diseases. We conduct our experiments on both syntheticand real-world microbiome datasets.    ",2022/03/02,Machine Learning,62,
41,On Practical Reinforcement Learning Provable Robustness Scalability and Statistical Efficiency,Thanh NguyenTang,Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML),"  This thesis rigorously studies fundamental reinforcement learning (RL)methods in modern practical considerations, including robust RL, distributionalRL, and offline RL with neural function approximation. The thesis firstprepares the readers with an overall overview of RL and key technicalbackground in statistics and optimization. In each of the settings, the thesismotivates the problems to be studied, reviews the current literature, providescomputationally efficient algorithms with provable efficiency guarantees, andconcludes with future research directions. The thesis makes fundamentalcontributions to the three settings above, both algorithmically, theoretically,and empirically, while staying relevant to practical considerations.    ",2022/03/03,Machine Learning,12,
42,Accelerated SGD for NonStronglyConvex Least Squares,Aditya Varre Nicolas Flammarion,Machine Learning (cs.LG); Optimization and Control (math.OC); Machine Learning (stat.ML),"  We consider stochastic approximation for the least squares regression problemin the non-strongly convex setting. We present the first practical algorithmthat achieves the optimal prediction error rates in terms of dependence on thenoise of the problem, as $O(d/t)$ while accelerating the forgetting of theinitial conditions to $O(d/t^2)$. Our new algorithm is based on a simplemodification of the accelerated gradient descent. We provide convergenceresults for both the averaged and the last iterate of the algorithm. In orderto describe the tightness of these new bounds, we present a matching lowerbound in the noiseless setting and thus show the optimality of our algorithm.    ",2022/03/03,Machine Learning,17,
43,Capturing Shape Information with MultiScale Topological Loss Terms for 3D Reconstruction,Dominik J E Waibel Scott Atwell Matthias Meier Carsten Marr Bastian Rieck,Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Image and Video Processing (eess.IV); Machine Learning (stat.ML),"  Reconstructing 3D objects from 2D images is both challenging for our brainsand machine learning algorithms. To support this spatial reasoning task,contextual information about the overall shape of an object is critical.However, such information is not captured by established loss terms (e.g. Diceloss). We propose to complement geometrical shape information by includingmulti-scale topological features, such as connected components, cycles, andvoids, in the reconstruction loss. Our method calculates topological featuresfrom 3D volumetric data based on cubical complexes and uses an optimaltransport distance to guide the reconstruction process. This topology-awareloss is fully differentiable, computationally efficient, and can be added toany neural network. We demonstrate the utility of our loss by incorporating itinto SHAPR, a model for predicting the 3D cell shape of individual cells basedon 2D microscopy images. Using a hybrid loss that leverages both geometricaland topological information of single objects to assess their shape, we findthat topological information substantially improves the quality ofreconstructions, thus highlighting its ability to extract more relevantfeatures from image datasets.    ",2022/03/03,Machine Learning,42,
44,FailSafe Generative Adversarial Imitation Learning,Philipp Geiger ChristophNikolas Straehle,Machine Learning (cs.LG); Multiagent Systems (cs.MA); Machine Learning (stat.ML),"  For flexible yet safe imitation learning (IL), we propose a modular approachthat uses a generative imitator policy with a safety layer, has an overallexplicit density/gradient, can therefore be end-to-end trained using generativeadversarial IL (GAIL), and comes with theoretical worst-case safety/robustnessguarantees. The safety layer's exact density comes from using a countablenon-injective gluing of piecewise differentiable injections and thechange-of-variables formula. The safe set (into which the safety layer maps) isinferred by sampling actions and their potential future fail-safe fallbackcontinuations, together with Lipschitz continuity and convexity arguments. Wealso provide theoretical bounds showing the advantage of using the safety layeralready during training (imitation error linear in the horizon) compared toonly using it at test time (quadratic error). In an experiment on challengingreal-world driver interaction data, we empirically demonstrate tractability,safety and imitation performance of our approach.    ",2022/03/03,Machine Learning,94,
45,Joint Probability Estimation Using Tensor Decomposition and Dictionaries,Shaan ul Haque Ajit Rajwade Karthik S Gurumoorthy,Machine Learning (cs.LG); Machine Learning (stat.ML),"  In this work, we study non-parametric estimation of joint probabilities of agiven set of discrete and continuous random variables from their (empiricallyestimated) 2D marginals, under the assumption that the joint probability couldbe decomposed and approximated by a mixture of product densities/massfunctions. The problem of estimating the joint probability density function(PDF) using semi-parametric techniques such as Gaussian Mixture Models (GMMs)is widely studied. However such techniques yield poor results when theunderlying densities are mixtures of various other families of distributionssuch as Laplacian or generalized Gaussian, uniform, Cauchy, etc. Further, GMMsare not the best choice to estimate joint distributions which are hybrid innature, i.e., some random variables are discrete while others are continuous.We present a novel approach for estimating the PDF using ideas from dictionaryrepresentations in signal processing coupled with low rank tensordecompositions. To the best our knowledge, this is the first work on estimatingjoint PDFs employing dictionaries alongside tensor decompositions. We create adictionary of various families of distributions by inspecting the data, and useit to approximate each decomposed factor of the product in the mixture. Ourapproach can naturally handle hybrid $N$-dimensional distributions. We test ourapproach on a variety of synthetic and real datasets to demonstrate itseffectiveness in terms of better classification rates and lower error rates,when compared to state of the art estimators.    ",2022/03/03,Machine Learning,129,
46,Continuous Relaxation For The Multivariate NonCentral Hypergeometric Distribution,Thomas M Sutter Laura Manduchi Alain Ryser Julia E Vogt,Machine Learning (cs.LG); Computation (stat.CO); Machine Learning (stat.ML),"  Partitioning a set of elements into a given number of groups of a prioriunknown sizes is an important task in many applications. Due to hardconstraints, it is a non-differentiable problem which prohibits its direct usein modern machine learning frameworks. Hence, previous works mostly fall backon suboptimal heuristics or simplified assumptions. The multivariatehypergeometric distribution offers a probabilistic formulation of how todistribute a given number of samples across multiple groups. Unfortunately, asa discrete probability distribution, it neither is differentiable. In thiswork, we propose a continuous relaxation for the multivariate non-centralhypergeometric distribution. We introduce an efficient and numerically stablesampling procedure. This enables reparameterized gradients for thehypergeometric distribution and its integration into automatic differentiationframeworks. We highlight the applicability and usability of the proposedformulation on two different common machine learning tasks.    ",2022/03/03,Machine Learning,52,
47,Early TimeSeries Classification Algorithms An Empirical Comparison,Charilaos Akasiadis Evgenios Kladis Evangelos Michelioudakis Elias Alevizos Alexander Artikis,Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML),"  Early Time-Series Classification (ETSC) is the task of predicting the classof incoming time-series by observing as few measurements as possible. Suchmethods can be employed to obtain classification forecasts in manytime-critical applications. However, available techniques are not equallysuitable for every problem, since differentiations in the data characteristicscan impact algorithm performance in terms of earliness, accuracy, F1-score, andtraining time. We evaluate six existing ETSC algorithms on publicly availabledata, as well as on two newly introduced datasets originating from the lifesciences and maritime domains. Our goal is to provide a framework for theevaluation and comparison of ETSC algorithms and to obtain intuition on howsuch approaches perform on real-life applications. The presented framework mayalso serve as a benchmark for new related techniques.    ",2022/03/03,Machine Learning,86,
48,Uniform Approximations for Randomized Hadamard Transforms with Applications,Yeshwanth Cherapanamjeri Jelani Nelson,Machine Learning (cs.LG); Computational Geometry (cs.CG); Data Structures and Algorithms (cs.DS); Machine Learning (stat.ML),"  Randomized Hadamard Transforms (RHTs) have emerged as a computationallyefficient alternative to the use of dense unstructured random matrices across arange of domains in computer science and machine learning. For severalapplications such as dimensionality reduction and compressed sensing, thetheoretical guarantees for methods based on RHTs are comparable to approachesusing dense random matrices with i.i.d.\ entries. However, several suchapplications are in the low-dimensional regime where the number of rows sampledfrom the matrix is rather small. Prior arguments are not applicable to thehigh-dimensional regime often found in machine learning applications likekernel approximation. Given an ensemble of RHTs with Gaussian diagonals,$\{M^i\}_{i = 1}^m$, and any $1$-Lipschitz function, $f: \mathbb{R} \to\mathbb{R}$, we prove that the average of $f$ over the entries of $\{M^i v\}_{i= 1}^m$ converges to its expectation uniformly over $\| v \| \leq 1$ at a ratecomparable to that obtained from using truly Gaussian matrices. We use ourinequality to then derive improved guarantees for two applications in thehigh-dimensional regime: 1) kernel approximation and 2) distance estimation.For kernel approximation, we prove the first \emph{uniform} approximationguarantees for random features constructed through RHTs lending theoreticaljustification to their empirical success while for distance estimation, ourconvergence result implies data structures with improved runtime guaranteesover previous work by the authors. We believe our general inequality is likelyto find use in other applications.    ",2022/03/03,Machine Learning,19,
49,Data Augmentation as Feature Manipulation a story of desert cows and grass cows,Ruoqi Shen Sébastien Bubeck Suriya Gunasekar,Machine Learning (cs.LG); Machine Learning (stat.ML),"  Data augmentation is a cornerstone of the machine learning pipeline, yet itstheoretical underpinnings remain unclear. Is it merely a way to artificiallyaugment the data set size? Or is it about encouraging the model to satisfycertain invariance? In this work we consider another angle, and we study theeffect of data augmentation on the dynamic of the learning process. We findthat data augmentation can alter the relative importance of various features,effectively making certain informative but hard to learn features more likelyto be captured in the learning process. Importantly, we show that this effectis more pronounced for non-linear models, such as neural networks. Our maincontribution is a detailed analysis of data augmentation on the learningdynamic for a two layer convolutional neural network in the recently proposedmulti-view model by Allen-Zhu and Li [2020]. We complement this analysis withfurther experimental evidence that data augmentation can be viewed as a form offeature manipulation.    ",2022/03/03,Machine Learning,100,
50,Representing Mixtures of Word Embeddings with Mixtures of Topic Embeddings,Dongsheng Wang Dandan Guo He Zhao Huangjie Zheng Korawat Tanwisuth Bo Chen Mingyuan Zhou,Machine Learning (cs.LG); Methodology (stat.ME); Machine Learning (stat.ML),"  A topic model is often formulated as a generative model that explains howeach word of a document is generated given a set of topics anddocument-specific topic proportions. It is focused on capturing the wordco-occurrences in a document and hence often suffers from poor performance inanalyzing short documents. In addition, its parameter estimation often relieson approximate posterior inference that is either not scalable or suffers fromlarge approximation error. This paper introduces a new topic-modeling frameworkwhere each document is viewed as a set of word embedding vectors and each topicis modeled as an embedding vector in the same embedding space. Embedding thewords and topics in the same vector space, we define a method to measure thesemantic difference between the embedding vectors of the words of a documentand these of the topics, and optimize the topic embeddings to minimize theexpected difference over all documents. Experiments on text analysisdemonstrate that the proposed method, which is amenable to mini-batchstochastic gradient descent based optimization and hence scalable to bigcorpora, provides competitive performance in discovering more coherent anddiverse topics and extracting better document representations.    ",2022/03/03,Machine Learning,29,
51,Kernel Density Estimation by Genetic Algorithm,Kiheiji Nishida,Methodology (stat.ME); Neural and Evolutionary Computing (cs.NE); Computation (stat.CO); Machine Learning (stat.ML),"  This study proposes a data condensation method for multivariate kerneldensity estimation by genetic algorithm. First, our proposed algorithmgenerates multiple subsamples of a given size with replacement from theoriginal sample. The subsamples and their constituting data points are regardedas $\it{chromosome}$ and $\it{gene}$, respectively, in the terminology ofgenetic algorithm. Second, each pair of subsamples breeds two new subsamples,where each data point faces either $\it{crossover}$, $\it{mutation}$, or$\it{reproduction}$ with a certain probability. The dominant subsamples interms of fitness values are inherited by the next generation. This process isrepeated generation by generation and brings the sparse representation ofkernel density estimator in its completion. We confirmed from simulationstudies that the resulting estimator can perform better than other well-knowndensity estimators.    ",2022/03/03,Machine Learning,83,
52,Largescale Optimization of Partial AUC in a Range of False Positive Rates,Yao Yao Qihang Lin Tianbao Yang,Machine Learning (cs.LG); Optimization and Control (math.OC); Machine Learning (stat.ML),"  The area under the ROC curve (AUC) is one of the most widely used performancemeasures for classification models in machine learning. However, it summarizesthe true positive rates (TPRs) over all false positive rates (FPRs) in the ROCspace, which may include the FPRs with no practical relevance in someapplications. The partial AUC, as a generalization of the AUC, summarizes onlythe TPRs over a specific range of the FPRs and is thus a more suitableperformance measure in many real-world situations. Although partial AUCoptimization in a range of FPRs had been studied, existing algorithms are notscalable to big data and not applicable to deep learning. To address thischallenge, we cast the problem into a non-smooth difference-of-convex (DC)program for any smooth predictive functions (e.g., deep neural networks), whichallowed us to develop an efficient approximated gradient descent method basedon the Moreau envelope smoothing technique, inspired by recent advances innon-smooth DC optimization. To increase the efficiency of large dataprocessing, we used an efficient stochastic block coordinate update in ouralgorithm. Our proposed algorithm can also be used to minimize the sum ofranked range loss, which also lacks efficient solvers. We established acomplexity of $\tilde O(1/\epsilon^6)$ for finding a nearly $\epsilon$-criticalsolution. Finally, we numerically demonstrated the effectiveness of ourproposed algorithms for both partial AUC maximization and sum of ranked rangeloss minimization.    ",2022/03/03,Machine Learning,88,
53,Scalable Bayesian Optimization Using Vecchia Approximations of Gaussian Processes,Felix Jimenez Matthias Katzfuss,Machine Learning (cs.LG); Machine Learning (stat.ML),"  Bayesian optimization is a technique for optimizing black-box targetfunctions. At the core of Bayesian optimization is a surrogate model thatpredicts the output of the target function at previously unseen inputs tofacilitate the selection of promising input values. Gaussian processes (GPs)are commonly used as surrogate models but are known to scale poorly with thenumber of observations. We adapt the Vecchia approximation, a popular GPapproximation from spatial statistics, to enable scalable high-dimensionalBayesian optimization. We develop several improvements and extensions,including training warped GPs using mini-batch gradient descent, approximateneighbor search, and selecting multiple input values in parallel. We focus onthe use of our warped Vecchia GP in trust-region Bayesian optimization viaThompson sampling. On several test functions and on two reinforcement-learningproblems, our methods compared favorably to the state of the art.    ",2022/03/02,Machine Learning,14,
54,A Survey on Offline Reinforcement Learning Taxonomy Review and Open Problems,Rafael Figueiredo Prudencio Marcos R O A Maximo Esther Luna Colombini,Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML),"  With the widespread adoption of deep learning, reinforcement learning (RL)has experienced a dramatic increase in popularity, scaling to previouslyintractable problems, such as playing complex games from pixel observations,sustaining conversations with humans, and controlling robotic agents. However,there is still a wide range of domains inaccessible to RL due to the high costand danger of interacting with the environment. Offline RL is a paradigm thatlearns exclusively from static datasets of previously collected interactions,making it feasible to extract policies from large and diverse trainingdatasets. Effective offline RL algorithms have a much wider range ofapplications than online RL, being particularly appealing for real-worldapplications such as education, healthcare, and robotics. In this work, wepropose a unifying taxonomy to classify offline RL methods. Furthermore, weprovide a comprehensive review of the latest algorithmic breakthroughs in thefield, and a review of existing benchmarks' properties and shortcomings.Finally, we provide our perspective on open problems and propose futureresearch directions for this rapidly growing field.    ",2022/03/02,Machine Learning,44,
55,Neural Galerkin Scheme with Active Learning for HighDimensional Evolution Equations,Joan Bruna Benjamin Peherstorfer Eric VandenEijnden,Numerical Analysis (math.NA); Machine Learning (cs.LG); Machine Learning (stat.ML),"  Machine learning methods have been shown to give accurate predictions in highdimensions provided that sufficient training data are available. Yet, manyinteresting questions in science and engineering involve situations whereinitially no data are available and the principal aim is to gather insightsfrom a known model. Here we consider this problem in the context of systemswhose evolution can be described by partial differential equations (PDEs). Weuse deep learning to solve these equations by generating data on-the-fly whenand where they are needed, without prior information about the solution. Theproposed Neural Galerkin schemes derive nonlinear dynamical equations for thenetwork weights by minimization of the residual of the time derivative of thesolution, and solve these equations using standard integrators for initialvalue problems. The sequential learning of the weights over time allows foradaptive collection of new input data for residual estimation. This step usesimportance sampling informed by the current state of the solution, in contrastwith other machine learning methods for PDEs that optimize the networkparameters globally in time. This active form of data acquisition is essentialto enable the approximation power of the neural networks and to break the curseof dimensionality faced by non-adaptative learning strategies. Theapplicability of the method is illustrated on several numerical examplesinvolving high-dimensional PDEs, including advection equations with manyvariables, as well as Fokker-Planck equations for systems with severalinteracting particles.    ",2022/03/02,Machine Learning,76,
56,License Incompatibilities in Software Ecosystems,RolfHelge Pfeiffer,Software Engineering (cs.SE),"  Contemporary software is characterized by reuse of components that aredeclared as dependencies and that are received from packagemanagers/registries, such as, NPM, PyPI, RubyGems, Maven Central, etc. Directand indirect dependency relations often form opaque dependency networks, thatsometimes lead to conflicting software licenses within these. In this paper, westudy license use and license incompatibilities between all components fromseven package registries (Cargo, Maven, NPM, NuGet, Packagist, PyPI, RubyGems)with a closer investigation of license incompatibilities caused by the GNUAffero General Public License (AGPL). We find that the relative amount of usedlicenses vary between ecosystems (permissive licenses such as MIT and Apacheare most frequent), that the number of direct license incompatibilities rangesfrom low 2.3% in Cargo to a large 20.8% in PyPI, that only a low amount ofdirect license incompatibilities are caused by AGPL licenses (max. 0.04% inPyPI), but that a whopping 6.62% of Maven packages are violating the AGPLlicense of an indirect dependency. Our results suggest that it is not toounlikely that applications that are reusing packages from PyPI or Maven areconfronted with license incompatibilities that could mean that applicationswould have to be open-sourced on distribution (PyPI) or as soon as they arepublicly available as web-applications (Maven).    ",2022/03/03,Software Engineering,112,
57,Computation offloading to hardware accelerators in Intel SGX and Gramine Library OS,Dmitrii Kuvaiskii Gaurav Kumar Mona Vij,Cryptography and Security (cs.CR); Software Engineering (cs.SE),"  The Intel Software Guard Extensions (SGX) technology enables applications torun in an isolated SGX enclave environment, with elevated confidentiality andintegrity guarantees. Gramine Library OS facilitates execution of existingunmodified applications in SGX enclaves, requiring only an accompanyingmanifest file that describes the application's security posture andconfiguration. However, Intel SGX is a CPU-only technology, thus Graminecurrently supports CPU-only workloads. To enable a broader class ofapplications that offload computations to hardware accelerators - GPU offload,NIC offload, FPGA offload, TPM communications - Gramine must be augmented withdevice-backed mmap support and generic ioctl support. In this paper, wedescribe the design and implementation of this newly added support, thecorresponding changes to the manifest-file syntax and the requisite deep copyalgorithm. We evaluate our implementation on Intel Media SDK workloads anddiscuss the encountered caveats and limitations. Finally, we outline a use casefor the presented mmap/ioctl support beyond mere device communication, namelythe mechanism to slice the application into the trusted enclave part (where thecore application executes) and the untrusted shared-memory part (where insecureshared libraries execute).    ",2022/03/02,Software Engineering,27,
58,A Survey of Analysis Methods for Security and Safety verification in IoT Systems,Lobna Abuserrieh Manar H Alalfi,Cryptography and Security (cs.CR); Software Engineering (cs.SE),"  Internet of Things (IoT) has been rapidly growing in the past few years inall life disciplines. IoT provides automation and smart control to its users indifferent domains such as home automation, healthcare systems, automotive, andmany more. Given the tremendous number of connected IoT devices, this growthleads to enormous automatic interactions among sizeable IoT apps in theirenvironment, making IoT apps more intelligent and more enjoyable to theirusers. But some unforeseen interactions of IoT apps and any potential maliciousbehaviour can seriously cause insecure and unsafe consequences to its users,primarily non-experts, who lack the required knowledge regarding the potentialimpact of their IoT automation processes. In this paper, we study the problemof security and safety verification of IoT systems. We survey techniques thatutilize program analysis to verify IoT applications' security and safetyproperties. The study proposes a set of categorization and classificationattributes to enhance our understanding of the research landscape in thisdomain. Moreover, we discuss the main challenges considered in the surveyedwork and potential solutions that could be adopted to ensure the security andsafety of IoT systems.    ",2022/03/03,Software Engineering,148,
59,NeuRecover RegressionControlled Repair of Deep Neural Networks with Training History,Shogo Tokui Susumu Tokumoto Akihito Yoshii Fuyuki Ishikawa Takao Nakagawa Kazuki Munakata Shinji Kikuchi,Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Software Engineering (cs.SE),"  Systematic techniques to improve quality of deep neural networks (DNNs) arecritical given the increasing demand for practical applications includingsafety-critical ones. The key challenge comes from the little controllabilityin updating DNNs. Retraining to fix some behavior often has a destructiveimpact on other behavior, causing regressions, i.e., the updated DNN fails withinputs correctly handled by the original one. This problem is crucial whenengineers are required to investigate failures in intensive assuranceactivities for safety or trust. Search-based repair techniques for DNNs havepotentials to tackle this challenge by enabling localized updates only on""responsible parameters"" inside the DNN. However, the potentials have not beenexplored to realize sufficient controllability to suppress regressions in DNNrepair tasks. In this paper, we propose a novel DNN repair method that makesuse of the training history for judging which DNN parameters should be changedor not to suppress regressions. We implemented the method into a tool calledNeuRecover and evaluated it with three datasets. Our method outperformed theexisting method by achieving often less than a quarter, even a tenth in somecases, number of regressions. Our method is especially effective when therepair requirements are tight to fix specific failure types. In such cases, ourmethod showed stably low rates (<2%) of regressions, which were in many cases atenth of regressions caused by retraining.    ",2022/03/01,Software Engineering,5,
60,Counterfactually Evaluating Explanations in Recommender Systems,Yuanshun Yao Chong Wang Hang Li,Artificial Intelligence (cs.AI),"  Modern recommender systems face an increasing need to explain theirrecommendations. Despite considerable progress in this area, evaluating thequality of explanations remains a significant challenge for researchers andpractitioners. Prior work mainly conducts human study to evaluate explanationquality, which is usually expensive, time-consuming, and prone to human bias.In this paper, we propose an offline evaluation method that can be computedwithout human involvement. To evaluate an explanation, our method quantifiesits counterfactual impact on the recommendation. To validate the effectivenessof our method, we carry out an online user study. We show that, compared toconventional methods, our method can produce evaluation scores more correlatedwith the real human judgments, and therefore can serve as a better proxy forhuman evaluation. In addition, we show that explanations with high evaluationscores are considered better by humans. Our findings highlight the promisingdirection of using the counterfactual approach as one possible way to evaluaterecommendation explanations.    ",2022/03/02,Artificial Intelligence,16,
61,Analytical Solutions for the Inverse Problem within Gradual Semantics,Nir Oren Bruno Yun Assaf Libman Murilo S Baptista,Artificial Intelligence (cs.AI),"  Gradual semantics within abstract argumentation associate a numeric scorewith every argument in a system, which represents the level of acceptability ofthis argument, and from which a preference ordering over arguments can bederived. While some semantics operate over standard argumentation frameworks,many utilise a weighted framework, where a numeric initial weight is associatedwith each argument. Recent work has examined the inverse problem within gradualsemantics. Rather than determining a preference ordering given an argumentationframework and a semantics, the inverse problem takes an argumentationframework, a gradual semantics, and a preference ordering as inputs, andidentifies what weights are needed to over arguments in the framework to obtainthe desired preference ordering. Existing work has attacked the inverse problemnumerically, using a root finding algorithm (the bisection method) to identifyappropriate initial weights. In this paper we demonstrate that for a class ofgradual semantics, an analytical approach can be used to solve the inverseproblem. Unlike the current state-of-the-art, such an analytic approach canrapidly find a solution, and is guaranteed to do so. In obtaining this result,we are able to prove several important properties which previous work had posedas conjectures.    ",2022/03/02,Artificial Intelligence,146,
62,Controlling the Focus of Pretrained Language Generation Models,Jiabao Ji Yoon Kim James Glass Tianxing He,Artificial Intelligence (cs.AI),"  The finetuning of pretrained transformer-based language generation models aretypically conducted in an end-to-end manner, where the model learns to attendto relevant parts of the input by itself. However, there does not exist amechanism to directly control the model's focus. This work aims to develop acontrol mechanism by which a user can select spans of context as ""highlights""for the model to focus on, and generate relevant output. To achieve this goal,we augment a pretrained model with trainable ""focus vectors"" that are directlyapplied to the model's embeddings, while the model itself is kept fixed. Thesevectors, trained on automatic annotations derived from attribution methods, actas indicators for context importance. We test our approach on two coregeneration tasks: dialogue response generation and abstractive summarization.We also collect evaluation data where the highlight-generation pairs areannotated by humans. Our experiments show that the trained focus vectors areeffective in steering the model to generate outputs that are relevant touser-selected highlights.    ",2022/03/02,Artificial Intelligence,22,
63,On the Configuration of More and Less Expressive Logic Programs,Carmine Dodaro Marco Maratea Mauro Vallati,Artificial Intelligence (cs.AI),"  The decoupling between the representation of a certain problem, i.e., itsknowledge model, and the reasoning side is one of main strong points ofmodel-based Artificial Intelligence (AI). This allows, e.g. to focus onimproving the reasoning side by having advantages on the whole solving process.Further, it is also well-known that many solvers are very sensitive to evensyntactic changes in the input. In this paper, we focus on improving thereasoning side by taking advantages of such sensitivity. We consider twowell-known model-based AI methodologies, SAT and ASP, define a number ofsyntactic features that may characterise their inputs, and use automatedconfiguration tools to reformulate the input formula or program. Results of awide experimental analysis involving SAT and ASP domains, taken from respectivecompetitions, show the different advantages that can be obtained by using inputreformulation and configuration. Under consideration in Theory and Practice ofLogic Programming (TPLP).    ",2022/03/02,Artificial Intelligence,140,
64,PKGM A Pretrained Knowledge Graph Model for Ecommerce Application,Wen Zhang ChiMan Wong Ganqinag Ye Bo Wen Hongting Zhou Wei Zhang Huajun Chen,Artificial Intelligence (cs.AI),"  In recent years, knowledge graphs have been widely applied as a uniform wayto organize data and have enhanced many tasks requiring knowledge. In onlineshopping platform Taobao, we built a billion-scale e-commerce product knowledgegraph. It organizes data uniformly and provides item knowledge services forvarious tasks such as item recommendation. Usually, such knowledge services areprovided through triple data, while this implementation includes (1) tediousdata selection works on product knowledge graph and (2) task model designingworks to infuse those triples knowledge. More importantly, product knowledgegraph is far from complete, resulting error propagation to knowledge enhancedtasks. To avoid these problems, we propose a Pre-trained Knowledge Graph Model(PKGM) for the billion-scale product knowledge graph. On the one hand, it couldprovide item knowledge services in a uniform way with service vectors forembedding-based and item-knowledge-related task models without accessing tripledata. On the other hand, it's service is provided based on implicitly completedproduct knowledge graph, overcoming the common the incomplete issue. We alsopropose two general ways to integrate the service vectors from PKGM intodownstream task models. We test PKGM in five knowledge-related tasks, itemclassification, item resolution, item recommendation, scene detection andsequential recommendation. Experimental results show that PKGM introducessignificant performance gains on these tasks, illustrating the useful ofservice vectors from PKGM.    ",2022/03/02,Artificial Intelligence,138,
65,NeuroSymbolic Verification of Deep Neural Networks,Xuan Xie Kristian Kersting Daniel Neider,Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Logic in Computer Science (cs.LO),"  Formal verification has emerged as a powerful approach to ensure the safetyand reliability of deep neural networks. However, current verification toolsare limited to only a handful of properties that can be expressed asfirst-order constraints over the inputs and output of a network. Whileadversarial robustness and fairness fall under this category, many real-worldproperties (e.g., ""an autonomous vehicle has to stop in front of a stop sign"")remain outside the scope of existing verification technology. To mitigate thissevere practical restriction, we introduce a novel framework for verifyingneural networks, named neuro-symbolic verification. The key idea is to useneural networks as part of the otherwise logical specification, enabling theverification of a wide variety of complex, real-world properties, including theone above. Moreover, we demonstrate how neuro-symbolic verification can beimplemented on top of existing verification infrastructure for neural networks,making our framework easily accessible to researchers and practitioners alike.    ",2022/03/02,Artificial Intelligence,106,
66,ResponsibleAIbyDesign a Pattern Collection for Designing Responsible AI Systems,Qinghua Lu Liming Zhu Xiwei Xu Jon Whittle,Artificial Intelligence (cs.AI),"  Although AI has significant potential to transform society, there are seriousconcerns about its ability to behave and make decisions responsibly. Manyethical regulations, principles, and guidelines for responsible AI have beenissued recently. However, these principles are high-level and difficult to putinto practice. In the meantime much effort has been put into responsible AIfrom the algorithm perspective, but they are limited to a small subset ofethical principles amenable to mathematical analysis. Responsible AI issues gobeyond data and algorithms and are often at the system-level crosscutting manysystem components and the entire software engineering lifecycle. Based on theresult of a systematic literature review, this paper identifies one missingelement as the system-level guidance: how to design the architecture ofresponsible AI systems. We present a summary of design patterns that can beembedded into the AI systems as product features to contribute toresponsible-AI-by-design.    ",2022/03/02,Artificial Intelligence,142,
67,Computerization of Clinical Pathways A Literature Review and Directions for Future Research,Ayman Alahmar Ola Alkhatib,Artificial Intelligence (cs.AI),"  Clinical Pathways (CP) are medical management plans developed to standardizepatient treatment activities, optimize resource usage, reduce expenses, andimprove the quality of healthcare services. Most CPs currently in use arepaper-based documents (i.e., not computerized). CP computerization has been anactive research topic since the inception of CP use in hospitals. Thisliterature review research aims to examine studies that focused on CPcomputerization and offers recommendations for future research in thisimportant research area. Some critical research suggestions includecentralizing computerized CPs in Healthcare Information Systems (HIS), CP termstandardization using international medical terminology systems, developing aglobal CP-specific digital coding system, creating a unified CP meta-ontology,developing independent Clinical Pathway Management Systems (CPMS), andsupporting CPMSs with machine learning sub-systems.    ",2022/03/02,Artificial Intelligence,150,
68,HighMMT Towards Modality and Task Generalization for HighModality Representation Learning,Paul Pu Liang Yiwei Lyu Xiang Fan Shengtong Mo Dani Yogatama LouisPhilippe Morency Ruslan Salakhutdinov,Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM),"  Learning multimodal representations involves discovering correspondences andintegrating information from multiple heterogeneous sources of data. Whilerecent research has begun to explore the design of more general-purposemultimodal models (contrary to prior focus on domain and modality-specificarchitectures), these methods are still largely focused on a small set ofmodalities in the language, vision, and audio space. In order to accelerategeneralization towards diverse and understudied modalities, we investigatemethods for high-modality (a large set of diverse modalities) andpartially-observable (each task only defined on a small subset of modalities)scenarios. To tackle these challenges, we design a general multimodal modelthat enables multitask and transfer learning: multitask learning with sharedparameters enables stable parameter counts (addressing scalability), andcross-modal transfer learning enables information sharing across modalities andtasks (addressing partial observability). Our resulting model generalizesacross text, image, video, audio, time-series, sensors, tables, and setmodalities from different research areas, improves the tradeoff betweenperformance and efficiency, transfers to new modalities and tasks, and revealssurprising insights on the nature of information sharing in multitask models.We release our code and benchmarks which we hope will present a unifiedplatform for subsequent theoretical and empirical analysis:this https URL.    ",2022/03/02,Artificial Intelligence,135,
69,DNDETR Accelerate DETR Training by Introducing Query DeNoising,Feng Li Hao Zhang Shilong Liu Jian Guo Lionel M Ni Lei Zhang,Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI),"  We present in this paper a novel denoising training method to speedup DETR(DEtection TRansformer) training and offer a deepened understanding of the slowconvergence issue of DETR-like methods. We show that the slow convergenceresults from the instability of bipartite graph matching which causesinconsistent optimization goals in early training stages. To address thisissue, except for the Hungarian loss, our method additionally feedsground-truth bounding boxes with noises into Transformer decoder and trains themodel to reconstruct the original boxes, which effectively reduces thebipartite graph matching difficulty and leads to a faster convergence. Ourmethod is universal and can be easily plugged into any DETR-like methods byadding dozens of lines of code to achieve a remarkable improvement. As aresult, our DN-DETR results in a remarkable improvement ($+1.9$AP) under thesame setting and achieves the best result (AP $43.4$ and $48.6$ with $12$ and$50$ epochs of training respectively) among DETR-like methods with ResNet-$50$backbone. Compared with the baseline under the same setting, DN-DETR achievescomparable performance with $50\%$ training epochs. Code is available at\url{this https URL}.    ",2022/03/02,Artificial Intelligence,147,
70,Pareto Frontier Approximation Network PANet to Solve Biobjective TSP,Ishaan Mehta Sajad Saeedi,Robotics (cs.RO); Artificial Intelligence (cs.AI),"  Travelling salesperson problem (TSP) is a classic resource allocation problemused to find an optimal order of doing a set of tasks while minimizing (ormaximizing) an associated objective function. It is widely used in robotics forapplications such as planning, scheduling etc. In this work, we solve TSP fortwo objectives using reinforcement learning. Often in multi objectiveoptimization problems, the associated objective functions can be conflicting innature. In such cases, the optimality is defined in terms of Pareto optimality.A set of these Pareto Optimal solutions in the objective space form a Paretofront (or frontier). Each solution has its own trade off. } In this work, wepresent PA-Net, a network that generates good approximations of the Paretofront for the bi-objective travelling salesperson problem (BTSP). Firstly, BTSPis converted into a constrained optimization problem. We then train our networkto solve this constrained problem using the Lagrangian relaxation and policygradient. With PA-Net we are able to generate good quality Pareto fronts withfast inference times. Finally, we present the application of PA-Net to findoptimal visiting order in a robotic navigation task/coverage planning.    ",2022/03/02,Artificial Intelligence,70,
71,Half Wavelet Attention on MNet for LowLight Image Enhancement,ChiMao Fan TsungJung Liu KuanHsien Liu,Image and Video Processing (eess.IV); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM),"  Low-Light Image Enhancement is a computer vision task which intensifies thedark images to appropriate brightness. It can also be seen as an ill-posedproblem in image restoration domain. With the success of deep neural networks,the convolutional neural networks surpass the traditional algorithm-basedmethods and become the mainstream in the computer vision area. To advance theperformance of enhancement algorithms, we propose an image enhancement network(HWMNet) based on an improved hierarchical model: M-Net+. Specifically, we usea half wavelet attention block on M-Net+ to enrich the features from waveletdomain. Furthermore, our HWMNet has competitive performance results on twoimage enhancement datasets in terms of quantitative metrics and visual quality.The source code and pretrained model are available atthis https URL.    ",2022/03/02,Artificial Intelligence,54,
72,Providing Insights for OpenResponse Surveys via EndtoEnd ContextAware Clustering,Soheil Esmaeilzadeh Brian Williams Davood Shamsi Onar Vikingstad,Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL),"  Teachers often conduct surveys in order to collect data from a predefinedgroup of students to gain insights into topics of interest. When analyzingsurveys with open-ended textual responses, it is extremely time-consuming,labor-intensive, and difficult to manually process all the responses into aninsightful and comprehensive report. In the analysis step, traditionally, theteacher has to read each of the responses and decide on how to group them inorder to extract insightful information. Even though it is possible to groupthe responses only using certain keywords, such an approach would be limitedsince it not only fails to account for embedded contexts but also cannot detectpolysemous words or phrases and semantics that are not expressible in singlewords. In this work, we present a novel end-to-end context-aware framework thatextracts, aggregates, and abbreviates embedded semantic patterns inopen-response survey data. Our framework relies on a pre-trained naturallanguage model in order to encode the textual data into semantic vectors. Theencoded vectors then get clustered either into an optimally tuned number ofgroups or into a set of groups with pre-specified titles. In the former case,the clusters are then further analyzed to extract a representative set ofkeywords or summary sentences that serve as the labels of the clusters. In ourframework, for the designated clusters, we finally provide context-awarewordclouds that demonstrate the semantically prominent keywords within eachgroup. Honoring user privacy, we have successfully built the on-deviceimplementation of our framework suitable for real-time analysis on mobiledevices and have tested it on a synthetic dataset. Our framework reduces thecosts at-scale by automating the process of extracting the most insightfulinformation pieces from survey data.    ",2022/03/02,Artificial Intelligence,98,
73,The role of haptic communication in dyadic collaborative object manipulation tasks,Yiming Liu Raz Leib William Dudley Ali Shafti A Aldo Faisal David W Franklin,Robotics (cs.RO); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC),"  Intuitive and efficient physical human-robot collaboration relies on themutual observability of the human and the robot, i.e. the two entities beingable to interpret each other's intentions and actions. This is remedied by amyriad of methods involving human sensing or intention decoding, as well ashuman-robot turn-taking and sequential task planning. However, the physicalinteraction establishes a rich channel of communication through forces, torquesand haptics in general, which is often overlooked in industrial implementationsof human-robot interaction. In this work, we investigate the role of haptics inhuman collaborative physical tasks, to identify how to integrate physicalcommunication in human-robot teams. We present a task to balance a ball at atarget position on a board either bimanually by one participant, or dyadicallyby two participants, with and without haptic information. The task requiresthat the two sides coordinate with each other, in real-time, to balance theball at the target. We found that with training the completion time and numberof velocity peaks of the ball decreased, and that participants gradually becameconsistent in their braking strategy. Moreover we found that the presence ofhaptic information improved the performance (decreased completion time) and ledto an increase in overall cooperative movements. Overall, our results show thathumans can better coordinate with one another when haptic feedback isavailable. These results also highlight the likely importance of hapticcommunication in human-robot physical interaction, both as a tool to inferhuman intentions and to make the robot behaviour interpretable to humans.    ",2022/03/02,Artificial Intelligence,14,
74,Deep Temporal Interpolation of Radarbased Precipitation,Michiaki Tatsubori Takao Moriyama Tatsuya Ishikawa Paolo Fraccaro Anne Jones Blair Edwards Julian Kuehnert Sekou L Remy,Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG),"  When providing the boundary conditions for hydrological flood models andestimating the associated risk, interpolating precipitation at very hightemporal resolutions (e.g. 5 minutes) is essential not to miss the cause offlooding in local regions. In this paper, we study optical flow-basedinterpolation of globally available weather radar images from satellites. Theproposed approach uses deep neural networks for the interpolation of multiplevideo frames, while terrain information is combined with temporarilycoarse-grained precipitation radar observation as inputs for self-supervisedtraining. An experiment with the Meteonet radar precipitation dataset for theflood risk simulation in Aude, a department in Southern France (2018),demonstrated the advantage of the proposed method over a linear interpolationbaseline, with up to 20% error reduction.    ",2022/03/01,Artificial Intelligence,109,
75,WaveYNet Physicsaugmented deep learning for highspeed electromagnetic simulation and optimization,Mingkun Chen Robert Lupoiu Chenkai Mao DerHan Huang Jiaqi Jiang Philippe Lalanne Jonathan A Fan,Applied Physics (physics.app-ph); Artificial Intelligence (cs.AI); Computational Physics (physics.comp-ph),"  The calculation of electromagnetic field distributions within structuredmedia is central to the optimization and validation of photonic devices. Weintroduce WaveY-Net, a hybrid data- and physics-augmented convolutional neuralnetwork that can predict electromagnetic field distributions with ultra fastspeeds and high accuracy for entire classes of dielectric photonic structures.This accuracy is achieved by training the neural network to learn only themagnetic near-field distributions of a system and to use a discrete formalismof Maxwell's equations in two ways: as physical constraints in the lossfunction and as a means to calculate the electric fields from the magneticfields. As a model system, we construct a surrogate simulator for periodicsilicon nanostructure arrays and show that the high speed simulator can bedirectly and effectively used in the local and global freeform optimization ofmetagratings. We anticipate that physics-augmented networks will serve as aviable Maxwell simulator replacement for many classes of photonic systems,transforming the way they are designed.    ",2022/03/02,Artificial Intelligence,77,
76,On the Optimization Landscape of Neural Collapse under MSE Loss Global Optimality with Unconstrained Features,Jinxin Zhou Xiao Li Tianyu Ding Chong You Qing Qu Zhihui Zhu,Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Information Theory (cs.IT); Optimization and Control (math.OC); Machine Learning (stat.ML),"  When training deep neural networks for classification tasks, an intriguingempirical phenomenon has been widely observed in the last-layer classifiers andfeatures, where (i) the class means and the last-layer classifiers all collapseto the vertices of a Simplex Equiangular Tight Frame (ETF) up to scaling, and(ii) cross-example within-class variability of last-layer activations collapsesto zero. This phenomenon is called Neural Collapse (NC), which seems to takeplace regardless of the choice of loss functions. In this work, we justify NCunder the mean squared error (MSE) loss, where recent empirical evidence showsthat it performs comparably or even better than the de-facto cross-entropyloss. Under a simplified unconstrained feature model, we provide the firstglobal landscape analysis for vanilla nonconvex MSE loss and show that the(only!) global minimizers are neural collapse solutions, while all othercritical points are strict saddles whose Hessian exhibit negative curvaturedirections. Furthermore, we justify the usage of rescaled MSE loss by probingthe optimization landscape around the NC solutions, showing that the landscapecan be improved by tuning the rescaling hyperparameters. Finally, ourtheoretical findings are experimentally verified on practical networkarchitectures.    ",2022/03/02,Artificial Intelligence,145,
77,Audio Selfsupervised Learning A Survey,Shuo Liu Adria MallolRagolta Emilia ParadaCabeleiro Kun Qian Xin Jing Alexander Kathan Bin Hu Bjoern W Schuller,Sound (cs.SD); Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS),"  Inspired by the humans' cognitive ability to generalise knowledge and skills,Self-Supervised Learning (SSL) targets at discovering general representationsfrom large-scale data without requiring human annotations, which is anexpensive and time consuming task. Its success in the fields of computer visionand natural language processing have prompted its recent adoption into thefield of audio and speech processing. Comprehensive reviews summarising theknowledge in audio SSL are currently missing. To fill this gap, in the presentwork, we provide an overview of the SSL methods used for audio and speechprocessing applications. Herein, we also summarise the empirical works thatexploit the audio modality in multi-modal SSL frameworks, and the existingsuitable benchmarks to evaluate the power of SSL in the computer auditiondomain. Finally, we discuss some open problems and point out the futuredirections on the development of audio SSL.    ",2022/03/02,Artificial Intelligence,60,
78,AvantSatie Using ERIK to encode taskrelevant expressivity into the animation of autonomous social robots,Tiago Ribeiro Ana Paiva,Robotics (cs.RO); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC),"  ERIK is an expressive inverse kinematics technique that has been previouslypresented and evaluated both algorithmically and in a limited user-interactionscenario. It allows autonomous social robots to convey posture-based expressiveinformation while gaze-tracking users. We have developed a new scenario aimedat further validating some of the unsupported claims from the previousscenario. Our experiment features a fully autonomous Adelino robot, andconcludes that ERIK can be used to direct a user's choice of actions duringexecution of a given task, fully through its non-verbal expressive queues.    ",2022/03/02,Artificial Intelligence,16,
79,Engineering the Neural Automatic Passenger Counter,Nico Jahn Michael Siebert,Machine Learning (cs.LG); Artificial Intelligence (cs.AI),"  Automatic passenger counting (APC) in public transportation has beenapproached with various machine learning and artificial intelligence methodssince its introduction in the 1970s. While equivalence testing is becoming morepopular than difference detection (Student's t-test), the former is much moredifficult to pass to ensure low user risk. On the other hand, recentdevelopments in artificial intelligence have led to algorithms that promisemuch higher counting quality (lower bias). However, gradient-based methods(including Deep Learning) have one limitation: they typically run into localoptima. In this work, we explore and exploit various aspects of machinelearning to increase reliability, performance, and counting quality. We performa grid search with several fundamental parameters: the selection and size ofthe training set, which is similar to cross-validation, and the initial networkweights and randomness during the training process. Using this experiment, weshow how aggregation techniques such as ensemble quantiles can reduce bias, andwe give an idea of the overall spread of the results. We utilize the testsuccess chance, a simulative metric based on the empirical distribution. Wealso employ a post-training Monte Carlo quantization approach and introducecumulative summation to turn counting into a stationary method and allowunbounded counts.    ",2022/03/02,Artificial Intelligence,69,
80,InsertionNet 20 Minimal Contact MultiStep Insertion Using Multimodal Multiview Sensory Input,Oren Spector Vladimir Tchuiev Dotan Di Castro,Robotics (cs.RO); Artificial Intelligence (cs.AI),"  We address the problem of devising the means for a robot to rapidly andsafely learn insertion skills with just a few human interventions and withouthand-crafted rewards or demonstrations. Our InsertionNet version 2.0 providesan improved technique to robustly cope with a wide range of use-cases featuringdifferent shapes, colors, initial poses, etc. In particular, we present aregression-based method based on multimodal input from stereo perception andforce, augmented with contrastive learning for the efficient learning ofvaluable features. In addition, we introduce a one-shot learning technique forinsertion, which relies on a relation network scheme to better exploit thecollected data and to support multi-step insertion tasks. Our method improveson the results obtained with the original InsertionNet, achieving an almostperfect score (above 97.5$\%$ on 200 trials) in 16 real-life insertion taskswhile minimizing the execution time and contact during insertion. We furtherdemonstrate our method's ability to tackle a real-life 3-step insertion taskand perfectly solve an unseen insertion task without learning.    ",2022/03/02,Artificial Intelligence,112,
81,ParameterEfficient MixtureofExperts Architecture for Pretrained Language Models,ZeFeng Gao Peiyu Liu Wayne Xin Zhao ZhongYi Lu JiRong Wen,Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Quantum Physics (quant-ph),"  The state-of-the-art Mixture-of-Experts (short as MoE) architecture hasachieved several remarkable successes in terms of increasing model capacity.However, MoE has been hindered widespread adoption due to complexity,communication costs, and training instability. Here we present a novel MoEarchitecture based on matrix product operators (MPO) from quantum many-bodyphysics. It can decompose an original matrix into central tensors (containingthe core information) and auxiliary tensors (with only a small proportion ofparameters). With the decomposed MPO structure, we can reduce the parameters ofthe original MoE architecture by sharing a global central tensor across expertsand keeping expert-specific auxiliary tensors. We also design the gradient maskstrategy for the tensor structure of MPO to alleviate the overfitting problem.Experiments on the three well-known downstream natural language datasets basedon GPT2 show improved performance and efficiency in increasing model capacity(7.26x fewer parameters with the same amount of experts). We additionallydemonstrate an improvement in the positive transfer effects of our approach formulti-task learning.    ",2022/03/02,Artificial Intelligence,96,
82,Visionbased Largescale 3D Semantic Mapping for Autonomous Driving Applications,Qing Cheng Niclas Zeller Daniel Cremers,Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI),"  In this paper, we present a complete pipeline for 3D semantic mapping solelybased on a stereo camera system. The pipeline comprises a direct sparse visualodometry front-end as well as a back-end for global optimization including GNSSintegration, and semantic 3D point cloud labeling. We propose a simple buteffective temporal voting scheme which improves the quality and consistency ofthe 3D point labels. Qualitative and quantitative evaluations of our pipelineare performed on the KITTI-360 dataset. The results show the effectiveness ofour proposed voting scheme and the capability of our pipeline for efficientlarge-scale 3D semantic mapping. The large-scale mapping capabilities of ourpipeline is furthermore demonstrated by presenting a very large-scale semanticmap covering 8000 km of roads generated from data collected by a fleet ofvehicles.    ",2022/03/02,Artificial Intelligence,122,
83,OnDevice Learning A Neural Network Based FieldTrainable Edge AI,Hiroki Matsutani Mineto Tsukada Masaaki Kondo,Machine Learning (cs.LG); Artificial Intelligence (cs.AI),"  In real-world edge AI applications, their accuracy is often affected byvarious environmental factors, such as noises, location/calibration of sensors,and time-related changes. This article introduces a neural network basedon-device learning approach to address this issue without going deep. Ourapproach is quite different from de facto backpropagation based training buttailored for low-end edge devices. This article introduces its algorithm andimplementation on a wireless sensor node consisting of Raspberry Pi Pico andlow-power wireless module. Experiments using vibration patterns of rotatingmachines demonstrate that retraining by the on-device learning significantlyimproves an anomaly detection accuracy at a noisy environment while savingcomputation and communication costs for low power.    ",2022/03/02,Artificial Intelligence,74,
84,Satellite Image and Machine Learning based Knowledge Extraction in the Poverty and Welfare Domain,Ola Hall Mattias Ohlsson Thortseinn Rögnvaldsson,Computers and Society (cs.CY); Artificial Intelligence (cs.AI); General Economics (econ.GN),"  Recent advances in artificial intelligence and machine learning have createda step change in how to measure human development indicators, in particularasset based poverty. The combination of satellite imagery and machine learninghas the capability to estimate poverty at a level similar to what is achievedwith workhorse methods such as face-to-face interviews and household surveys.An increasingly important issue beyond static estimations is whether thistechnology can contribute to scientific discovery and consequently newknowledge in the poverty and welfare domain. A foundation for achievingscientific insights is domain knowledge, which in turn translates intoexplainability and scientific consistency. We review the literature focusing onthree core elements relevant in this context: transparency, interpretability,and explainability and investigate how they relates to the poverty, machinelearning and satellite imagery nexus. Our review of the field shows that thestatus of the three core elements of explainable machine learning(transparency, interpretability and domain knowledge) is varied and does notcompletely fulfill the requirements set up for scientific insights anddiscoveries. We argue that explainability is essential to support widerdissemination and acceptance of this research, and explainability means morethan just interpretability.    ",2022/03/02,Artificial Intelligence,103,
85,Mobile device users susceptibility to phishing attacks,F Ley Sylvester,Cryptography and Security (cs.CR),"The mobile device is one of the fasted growing technologies that is widelyused in a diversifying sector. Mobile devices are used for everyday life, suchas personal information exchange - chatting, email, shopping, and mobilebanking, contributing to information security threats. Users' behavior caninfluence information security threats. More research is needed to understandusers' threat avoidance behavior and motivation. Using Technology threatavoidance theory (TTAT), this study assessed factors that influenced mobiledevice users' threat avoidance motivations and behaviors as it relates tophishing attacks. From the data collected from 137 mobile device users using aquestionnaire, the findings indicate that (1) mobile device users' perceivedsusceptibility and severity of phishing attacks have a significant correlationwith a users' perception of the threat; (2) mobile device users' motivation toavoid a threat is correlated to a users' behavior in avoiding threat; and (3) amobile device user's susceptibility to phishing attacks can be reduced by theirperception of the threat. These findings reveal that a user's perception ofthreat increases if they perceive that the consequence of such threat to theirmobile devices will be severe, thereby increasing a user's motivation andbehavior to avoid phishing attack threats. This study is beneficial to mobiledevice users in personal and organizational settings.",3/2/2022,Cryptography and Security,84,
86,Computation offloading to hardware accelerators in Intel SGX and Gramine Library OS,Dmitrii Kuvaiskii Gaurav Kumar Mona Vij,Cryptography and Security (cs.CR); Software Engineering (cs.SE),"The Intel Software Guard Extensions (SGX) technology enables applications torun in an isolated SGX enclave environment, with elevated confidentiality andintegrity guarantees. Gramine Library OS facilitates execution of existingunmodified applications in SGX enclaves, requiring only an accompanyingmanifest file that describes the application's security posture andconfiguration. However, Intel SGX is a CPU-only technology, thus Graminecurrently supports CPU-only workloads. To enable a broader class ofapplications that offload computations to hardware accelerators - GPU offload,NIC offload, FPGA offload, TPM communications - Gramine must be augmented withdevice-backed mmap support and generic ioctl support. In this paper, wedescribe the design and implementation of this newly added support, thecorresponding changes to the manifest-file syntax and the requisite deep copyalgorithm. We evaluate our implementation on Intel Media SDK workloads anddiscuss the encountered caveats and limitations. Finally, we outline a use casefor the presented mmap/ioctl support beyond mere device communication, namelythe mechanism to slice the application into the trusted enclave part (where thecore application executes) and the untrusted shared-memory part (where insecureshared libraries execute).",3/2/2022,Cryptography and Security,75,
87,Detecting HighQuality GANGenerated Face Images using Neural Networks,Ehsan Nowroozi Mauro Conti Yassine Mekdad,Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Image and Video Processing (eess.IV),"In the past decades, the excessive use of the last-generation GAN (GenerativeAdversarial Networks) models in computer vision has enabled the creation ofartificial face images that are visually indistinguishable from genuine ones.These images are particularly used in adversarial settings to create fakesocial media accounts and other fake online profiles. Such malicious activitiescan negatively impact the trustworthiness of users identities. On the otherhand, the recent development of GAN models may create high-quality face imageswithout evidence of spatial artifacts. Therefore, reassembling uniform colorchannel correlations is a challenging research problem. To face thesechallenges, we need to develop efficient tools able to differentiate betweenfake and authentic face images. In this chapter, we propose a new strategy todifferentiate GAN-generated images from authentic images by leveraging spectralband discrepancies, focusing on artificial face image synthesis. In particular,we enable the digital preservation of face images using the Cross-bandco-occurrence matrix and spatial co-occurrence matrix. Then, we implement thesetechniques and feed them to a Convolutional Neural Networks (CNN) architectureto identify the real from artificial faces. Additionally, we show that theperformance boost is particularly significant and achieves more than 92% indifferent post-processing environments. Finally, we provide several researchobservations demonstrating that this strategy improves a comparable detectionmethod based only on intra-band spatial co-occurrences.",3/3/2022,Cryptography and Security,11,
88,Difficult for Thee But Not for Me Measuring the Difficulty and User Experience of Remediating Persistent IoT Malware,Elsa Rodríguez Max Fukkink Simon Parkin Michel van Eeten Carlos Gañán,Cryptography and Security (cs.CR); Human-Computer Interaction (cs.HC),"Consumer IoT devices may suffer malware attacks, and be recruited intobotnets or worse. There is evidence that generic advice to device owners toaddress IoT malware can be successful, but this does not account for emergingforms of persistent IoT malware. Less is known about persistent malware, whichresides on persistent storage, requiring targeted manual effort to remove it.This paper presents a field study on the removal of persistent IoT malware byconsumers. We partnered with an ISP to contrast remediation times of 760customers across three malware categories: Windows malware, non-persistent IoTmalware, and persistent IoT malware. We also contacted ISP customers identifiedas having persistent IoT malware on their network-attached storage devices,specifically QSnatch. We found that persistent IoT malware exhibits a meaninfection duration many times higher than Windows or Mirai malware; QSnatch hasa survival probability of 30% after 180 days, whereby most if not all otherobserved malware types have been removed. For interviewed device users, QSnatchinfections lasted longer, so are apparently more difficult to get rid of, yetparticipants did not report experiencing difficulty in following notificationinstructions. We see two factors driving this paradoxical finding: First, mostusers reported having high technical competency. Also, we found evidence ofplanning behavior for these tasks and the need for multiple notifications. Ourfindings demonstrate the critical nature of interventions from outside forpersistent malware, since automatic scan of an AV tool or a power cycle, likewe are used to for Windows malware and Mirai infections, will not solvepersistent IoT malware infections.",3/3/2022,Cryptography and Security,41,
89,SoK SCT Auditing in Certificate Transparency,Sarah Meiklejohn Joe DeBlasio Devon OBrien Chris Thompson Kevin Yeo Emily Stark,Cryptography and Security (cs.CR),"The Web public key infrastructure is essential to providing securecommunication on the Internet today, and certificate authorities play a crucialrole in this ecosystem by issuing certificates. These authorities may misissuecertificates or suffer misuse attacks, however, which has given rise to theCertificate Transparency (CT) project. The goal of CT is to store all issuedcertificates in public logs, which can then be checked for the presence ofpotentially misissued certificates. Thus, the requirement that a givencertificate is indeed in one (or several) of these logs lies at the core of CT.In its current deployment, however, most individual clients do not check thatthe certificates they see are in logs, as requesting a proof of inclusiondirectly reveals the certificate and thus creates the clear potential for aviolation of that client's privacy. In this paper, we explore the techniquesthat have been proposed for privacy-preserving auditing of certificateinclusion, focusing on their effectiveness, efficiency, and suitability in anear-term deployment. In doing so, we also explore the parallels with relatedproblems involving browser clients. Guided by a set of constraints that wedevelop, we ultimately observe several key limitations in many proposals,ranging from their privacy provisions to the fact that they focus on theinteraction between a client and a log but leave open the question of how aclient could privately report any certificates that are missing.",3/3/2022,Cryptography and Security,111,
90,5G Network Slice Isolation,Stan Wong Bin Han Hans D Schotten,Cryptography and Security (cs.CR); Networking and Internet Architecture (cs.NI),"This article reveals an adequate comprehension of basic defense, securitychallenges, 2 and attack vectors in deploying multi-network slicing. Networkslicing is a revolutionary concept 3 of providing mobile network on-demand andexpanding mobile networking business and services 4 to a new era. The newbusiness paradigm and service opportunities are encouraging vertical 5industries to join and develop their own mobile network capabilities forenhanced performances 6 that are coherent with their applications. However, anumber of security concerns are also raised 7 in this new era. In this article,we focus on the deployment of multi-network slicing with multi8 tenancy. Weidentify the security concerns, and discuss about the defense approaches suchas 9 network slice isolation and insulation in a multi-layer network slicingsecurity model. Also, we 10 identify the importance to appropriately select thenetwork slice isolation points, and propose 11 a generic framework to optimizethe isolation policy regarding the implementation cost while 12 guaranteeingthe security and performance requirements.",3/3/2022,Cryptography and Security,135,
91,How Do Organizations Seek Cyber Assurance Investigations on the Adoption of the Common Criteria and Beyond,Nan Sun ChangTsun Li Hin Chan Md Zahidul Islam Md Rafiqul Islam Warren Armstrong,Cryptography and Security (cs.CR),"Cyber assurance, which is the ability to operate under the onslaught of cyberattacks and other unexpected events, is essential for organizations facinginundating security threats on a daily basis. Organizations usually employmultiple strategies to conduct risk management to achieve cyber assurance.Utilizing cybersecurity standards and certifications can provide guidance forvendors to design and manufacture secure Information and CommunicationTechnology (ICT) products as well as provide a level of assurance of thesecurity functionality of the products for consumers. Hence, employing securitystandards and certifications is an effective strategy for risk management andcyber assurance. In this work, we begin with investigating the adoption ofcybersecurity standards and certifications by surveying 258 participants fromorganizations across various countries and sectors. Specifically, we identifyadoption barriers of the Common Criteria through the designed questionnaire.Taking into account the seven identified adoption barriers, we show therecommendations for promoting cybersecurity standards and certifications.Moreover, beyond cybersecurity standards and certifications, we shed light onother risk management strategies devised by our participants, which providesdirections on cybersecurity approaches for enhancing cyber assurance inorganizations.",3/3/2022,Cryptography and Security,119,
92,Security Analysis of Two Recent PairingFree Certificateless TwoParty Authenticated Key Agreement Protocols for Smart Grid,YongJin Kim DokJun An KumSok Sin YouJin Jong OkChol Ri,Cryptography and Security (cs.CR),"Smart grids are intelligent power transmission networks that monitor andcontrol communication participants and grid nodes to ensure bidirectional flowof information and power between all nodes. To secure the smart grid, it isvery important to design the key agreement protocol. The pairing-freecertificateless two-party authenticated key agreement protocol has been widelystudied and applied as a basic core protocol to protect the security of thesmart grid. Until now, various protocols have been proposed, and theseprotocols are being introduced and operated not only in smart grid, but also insmart cities, healthcare, and vehicle ad hoc networks. In this paper, weanalyzed the security properties of two recently proposed pairing-freecertificateless two-party authenticated key agreement protocols for Smart grid.According to our analysis, these two protocols are insecure against basicimpersonation attacks of malicious key-generator centers, man-in-the-middleattacks of malicious key generator centers, and key offset attacks. We alsofound and pointed out some errors in the descriptions of these protocols.",3/3/2022,Cryptography and Security,35,
93,Disperse rotation operator DRT and use in some stream ciphers,YongJin Kim YongHo Yon SonGyong Kim,Cryptography and Security (cs.CR),"The rotation operator is frequently used in several stream ciphers, includingHC-128, Rabbit, and Salsa20, the final candidates for eSTREAM. This is becausethe rotation operator (ROT) is simple but has very good dispersibility. In thispaper, we propose a disperse rotation operator (DRT), which has the samestructure as ROT but has better dispersibility. In addition, the use of DRTinstead of ROT has shown that the quality of the output stream of all threestream ciphers was significantly improved. However, the use of DRT instead ofROT in the HC-128 stream cipher prevents the expansion of differential attacksbased on LSB.",3/3/2022,Cryptography and Security,93,
94,A Survey of Analysis Methods for Security and Safety verification in IoT Systems,Lobna Abuserrieh Manar H Alalfi,Cryptography and Security (cs.CR); Software Engineering (cs.SE),"Internet of Things (IoT) has been rapidly growing in the past few years inall life disciplines. IoT provides automation and smart control to its users indifferent domains such as home automation, healthcare systems, automotive, andmany more. Given the tremendous number of connected IoT devices, this growthleads to enormous automatic interactions among sizeable IoT apps in theirenvironment, making IoT apps more intelligent and more enjoyable to theirusers. But some unforeseen interactions of IoT apps and any potential maliciousbehaviour can seriously cause insecure and unsafe consequences to its users,primarily non-experts, who lack the required knowledge regarding the potentialimpact of their IoT automation processes. In this paper, we study the problemof security and safety verification of IoT systems. We survey techniques thatutilize program analysis to verify IoT applications' security and safetyproperties. The study proposes a set of categorization and classificationattributes to enhance our understanding of the research landscape in thisdomain. Moreover, we discuss the main challenges considered in the surveyedwork and potential solutions that could be adopted to ensure the security andsafety of IoT systems.",3/3/2022,Cryptography and Security,126,
95,EnclaveTree Privacypreserving Data Stream Training and Inference Using TEE,Qifan Wang Shujie Cui Lei Zhou Ocean Wu Yonghua Zhu Giovanni Russello,Cryptography and Security (cs.CR),"The classification service over a stream of data is becoming an importantoffering for cloud providers, but users may encounter obstacles in providingsensitive data due to privacy concerns. While Trusted Execution Environments(TEEs) are promising solutions for protecting private data, they remainvulnerable to side-channel attacks induced by data-dependent access patterns.We propose a Privacy-preserving Data Stream Training and Inference scheme,called EnclaveTree, that provides confidentiality for user's data and thetarget models against a compromised cloud service provider. We design amatrix-based training and inference procedure to train the Hoeffding Tree (HT)model and perform inference with the trained model inside the trusted area ofTEEs, which provably prevent the exploitation of access-pattern-based attacks.The performance evaluation shows that EnclaveTree is practical for processingthe data streams with small or medium number of features. When there are lessthan 63 binary features, EnclaveTree is up to ${\thicksim}10{\times}$ and${\thicksim}9{\times}$ faster than naïve oblivious solution on training andinference, respectively.",3/2/2022,Cryptography and Security,7,
96,Detection of Word Adversarial Examples in Text Classification Benchmark and Baseline via Robust Density Estimation,KiYoon Yoo Jangho Kim Jiho Jang Nojun Kwak,Computation and Language (cs.CL); Cryptography and Security (cs.CR); Machine Learning (cs.LG),"Word-level adversarial attacks have shown success in NLP models, drasticallydecreasing the performance of transformer-based models in recent years. As acountermeasure, adversarial defense has been explored, but relatively fewefforts have been made to detect adversarial examples. However, detectingadversarial examples may be crucial for automated tasks (e.g. review sentimentanalysis) that wish to amass information about a certain population andadditionally be a step towards a robust defense system. To this end, we releasea dataset for four popular attack methods on four datasets and four models toencourage further research in this field. Along with it, we propose acompetitive baseline based on density estimation that has the highest AUC on 29out of 30 dataset-attack-model combinations. Source code is available inthis https URL.",3/3/2022,Cryptography and Security,17,
97,Quantum Proofs of Deletion for Learning with Errors,Alexander Poremba,Quantum Physics (quant-ph); Cryptography and Security (cs.CR),"Quantum information has the property that measurement is an inherentlydestructive process. This feature is most apparent in the principle ofcomplementarity, which states that mutually incompatible observables cannot bemeasured at the same time. Recent work by Broadbent and Islam (TCC 2020) buildson this aspect of quantum mechanics to realize a cryptographic notion calledcertified deletion. While this remarkable notion enables a classical verifierto be convinced that a (private-key) quantum ciphertext has been deleted by anuntrusted party, it offers no additional layer of functionality.In this work, we augment the proof-of-deletion paradigm with fullyhomomorphic encryption (FHE). This results in a new and powerful cryptographicnotion called fully homomorphic encryption with certified deletion -- aninteractive protocol which enables an untrusted quantum server to compute onencrypted data and, if requested, to simultaneously prove data deletion to aclient. Our main technical ingredient is an interactive protocol by which aquantum prover can convince a classical verifier that a sample from theLearning with Errors (LWE) distribution in the form of a quantum state wasdeleted. We introduce an encoding based on Gaussian coset states which ishighly generic and suggests that essentially any LWE-based cryptographicprimitive admits a classically-verifiable quantum proof of deletion. As anapplication of our protocol, we construct a Dual-Regev public-key encryptionscheme with certified deletion, which we then extend towards a (leveled) FHEscheme of the same type. Our construction achieves indistinguishableciphertexts in the semi-honest adversarial model, even if the secret key islater revealed after deletion has taken place.",3/3/2022,Cryptography and Security,99,
98,Private HighDimensional Hypothesis Testing,Shyam Narayanan,Data Structures and Algorithms (cs.DS); Cryptography and Security (cs.CR); Information Theory (cs.IT); Machine Learning (cs.LG); Statistics Theory (math.ST),"We provide improved differentially private algorithms for identity testing ofhigh-dimensional distributions. Specifically, for $d$-dimensional Gaussiandistributions with known covariance $\Sigma$, we can test whether thedistribution comes from $\mathcal{N}(\mu^*, \Sigma)$ for some fixed $\mu^*$ orfrom some $\mathcal{N}(\mu, \Sigma)$ with total variation distance at least$\alpha$ from $\mathcal{N}(\mu^*, \Sigma)$ with $(\varepsilon, 0)$-differentialprivacy, using only \[\tilde{O}\left(\frac{d^{1/2}}{\alpha^2} +\frac{d^{1/3}}{\alpha^{4/3} \cdot \varepsilon^{2/3}} + \frac{1}{\alpha \cdot\varepsilon}\right)\] samples if the algorithm is allowed to be computationallyinefficient, and only \[\tilde{O}\left(\frac{d^{1/2}}{\alpha^2} +\frac{d^{1/4}}{\alpha \cdot \varepsilon}\right)\] samples for a computationallyefficient algorithm. We also provide a matching lower bound showing that ourcomputationally inefficient algorithm has optimal sample complexity. We alsoextend our algorithms to various related problems, including mean testing ofGaussians with bounded but unknown covariance, uniformity testing of productdistributions over $\{\pm 1\}^d$, and tolerant testing.Our results improve over the previous best work of Canonne, Kamath, McMillan,Ullman, and Zakynthinou \cite{CanonneKMUZ20} for both computationally efficientand inefficient algorithms, and even our computationally efficient algorithmmatches the optimal \emph{non-private} sample complexity of$O\left(\frac{\sqrt{d}}{\alpha^2}\right)$ in many standard parameter settings.In addition, our results show that, surprisingly, private identity testing of$d$-dimensional Gaussians can be done with fewer samples than private identitytesting of discrete distributions over a domain of size $d$ \cite{AcharyaSZ18},which refutes a conjectured lower bound of Canonne et al. \cite{CanonneKMUZ20}.",3/3/2022,Cryptography and Security,134,
99,Label Leakage and Protection from Forward Embedding in Vertical Federated Learning,Jiankai Sun Xin Yang Yuanshun Yao Chong Wang,Machine Learning (cs.LG); Cryptography and Security (cs.CR),"Vertical federated learning (vFL) has gained much attention and been deployedto solve machine learning problems with data privacy concerns in recent years.However, some recent work demonstrated that vFL is vulnerable to privacyleakage even though only the forward intermediate embedding (rather than rawfeatures) and backpropagated gradients (rather than raw labels) arecommunicated between the involved participants. As the raw labels often containhighly sensitive information, some recent work has been proposed to prevent thelabel leakage from the backpropagated gradients effectively in vFL. However,these work only identified and defended the threat of label leakage from thebackpropagated gradients. None of these work has paid attention to the problemof label leakage from the intermediate embedding. In this paper, we propose apractical label inference method which can steal private labels effectivelyfrom the shared intermediate embedding even though some existing protectionmethods such as label differential privacy and gradients perturbation areapplied. The effectiveness of the label attack is inseparable from thecorrelation between the intermediate embedding and corresponding privatelabels. To mitigate the issue of label leakage from the forward embedding, weadd an additional optimization goal at the label party to limit the labelstealing ability of the adversary by minimizing the distance correlationbetween the intermediate embedding and corresponding private labels. Weconducted massive experiments to demonstrate the effectiveness of our proposedprotection methods.",3/2/2022,Cryptography and Security,4,
100,NearOptimal Correlation Clustering with Privacy,Vincent CohenAddad Chenglin Fan Silvio Lattanzi Slobodan Mitrović Ashkan NorouziFard Nikos Parotsidis Jakub Tarnawski,Machine Learning (cs.LG); Cryptography and Security (cs.CR); Data Structures and Algorithms (cs.DS),"Correlation clustering is a central problem in unsupervised learning, withapplications spanning community detection, duplicate detection, automatedlabelling and many more. In the correlation clustering problem one receives asinput a set of nodes and for each node a list of co-clustering preferences, andthe goal is to output a clustering that minimizes the disagreement with thespecified nodes' preferences. In this paper, we introduce a simple andcomputationally efficient algorithm for the correlation clustering problem withprovable privacy guarantees. Our approximation guarantees are stronger thanthose shown in prior work and are optimal up to logarithmic factors.",3/2/2022,Cryptography and Security,27,
101,Enhancing Adversarial Robustness for Deep Metric Learning,Mo Zhou Vishal M Patel,Machine Learning (cs.LG); Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV),"Owing to security implications of adversarial vulnerability, adversarialrobustness of deep metric learning models has to be improved. In order to avoidmodel collapse due to excessively hard examples, the existing defenses dismissthe min-max adversarial training, but instead learn from a weak adversaryinefficiently. Conversely, we propose Hardness Manipulation to efficientlyperturb the training triplet till a specified level of hardness for adversarialtraining, according to a harder benign triplet or a pseudo-hardness function.It is flexible since regular training and min-max adversarial training are itsboundary cases. Besides, Gradual Adversary, a family of pseudo-hardnessfunctions is proposed to gradually increase the specified hardness level duringtraining for a better balance between performance and robustness. Additionally,an Intra-Class Structure loss term among benign and adversarial examplesfurther improves model robustness and efficiency. Comprehensive experimentalresults suggest that the proposed method, although simple in its form,overwhelmingly outperforms the state-of-the-art defenses in terms ofrobustness, training efficiency, as well as performance on benign examples.",3/2/2022,Cryptography and Security,46,
102,PrivacyAware Crowd Labelling for Machine Learning Tasks,Giannis Haralabopoulos Ioannis Anagnostopoulos,Human-Computer Interaction (cs.HC); Cryptography and Security (cs.CR); Machine Learning (cs.LG); Social and Information Networks (cs.SI),"The extensive use of online social media has highlighted the importance ofprivacy in the digital space. As more scientists analyse the data created inthese platforms, privacy concerns have extended to data usage within theacademia. Although text analysis is a well documented topic in academicliterature with a multitude of applications, ensuring privacy of user-generatedcontent has been overlooked. Most sentiment analysis methods require emotionlabels, which can be obtained through crowdsourcing, where non-expertindividuals contribute to scientific tasks. The text itself has to be exposedto third parties in order to be labelled. In an effort to reduce the exposureof online users' information, we propose a privacy preserving text labellingmethod for varying applications, based in crowdsourcing. We transform text withdifferent levels of privacy, and analyse the effectiveness of thetransformation with regards to label correlation and consistency. Our resultssuggest that privacy can be implemented in labelling, retaining theannotational diversity and subjectivity of traditional labelling.",2/3/2022,Cryptography and Security,40,
103,Efficient Data Structures for Exploiting Sparsity and Structure in Representation of Polynomial Optimization Problems Implementation in SOSTOOLS,Declan Jagt Sachin Shivakumar Peter Seiler Matthew Peet,Optimization and Control (math.OC); Mathematical Software (cs.MS),"We present a new data structure for representation of polynomial variables inthe parsing of sum-of-squares (SOS) programs. In SOS programs, the variables$s(x;P)$ are polynomial in the independent variables $x$, but linear in thedecision variables $P$. Current SOS parsers, however, fail to exploit thesemi-linear structure of the polynomial variables, treating the decisionvariables as independent variables in their representation. This results inunnecessary overhead in storage and manipulation of the polynomial variables,prohibiting the parser from addressing larger-scale optimization problems. Toeliminate this computational overhead, we introduce a new representation ofpolynomial variables, the ""dpvar"" structure, that is affine in the decisionvariables. We show that the complexity of operations on variables in the dpvarrepresentation scales favorably with the number of decision variables. Wefurther show that the required memory for storing polynomial variables isrelatively small using the dpvar structure, particularly when exploiting theMATLAB sparse storage structure. Finally, we incorporate the dpvar datastructure into SOSTOOLS 4.00, and test the performance of the parser forseveral polynomial optimization problems.",3/3/2022,Math,129,
104,MooAFEM An object oriented Matlab code for higherorder nonlinear adaptive FEM,Michael Innerberger Dirk Praetorius,Numerical Analysis (math.NA); Mathematical Software (cs.MS),"We present an easily accessible, object oriented code (written exclusively inMatlab) for finite element simulations in 2D. The object oriented programmingparadigm allows for fast implementation of higher-order FEM on triangularmeshes for problems with very general coefficients. In particular, our code canhandle problems typically arising from iterative linearization methods used tosolve nonlinear PDEs. We explain the basic principles of our code and givenumerical experiments that underline its flexibility as well as its efficiency.",3/3/2022,Math,75,
105,Vertical Federated Principal Component Analysis and Its Kernel Extension on Featurewise Distributed Data,Yiuming Cheung Juyong Jiang Feng Yu Jian Lou,"Machine Learning (cs.LG); Distributed, Parallel, and Cluster Computing (cs.DC)","Despite enormous research interest and rapid application of federatedlearning (FL) to various areas, existing studies mostly focus on supervisedfederated learning under the horizontally partitioned local dataset setting.This paper will study the unsupervised FL under the vertically partitioneddataset setting. Accordingly, we propose the federated principal componentanalysis for vertically partitioned dataset (VFedPCA) method, which reduces thedimensionality across the joint datasets over all the clients and extracts theprincipal component feature information for downstream data analysis. Wefurther take advantage of the nonlinear dimensionality reduction and proposethe vertical federated advanced kernel principal component analysis (VFedAKPCA)method, which can effectively and collaboratively model the nonlinear natureexisting in many real datasets. In addition, we study two communicationtopologies. The first is a server-client topology where a semi-trusted servercoordinates the federated training, while the second is the fully-decentralizedtopology which further eliminates the requirement of the server by allowingclients themselves to communicate with their neighbors. Extensive experimentsconducted on five types of real-world datasets corroborate the efficacy ofVFedPCA and VFedAKPCA under the vertically partitioned FL setting. Code isavailable at: this https URL",3/3/2022,Cluster,12,